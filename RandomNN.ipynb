{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from helpers import count_unique_words, count_unique_ngrams, \\\n",
    "            build_unique_ngrams, create_sentence_vectors, create_sentence_vectors_submission\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import gensim   # Not sure whether it is better to use gensim or tensorflow :/\n",
    "import logging\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Embedding, Input, Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"dataframes/full_df_cleaned_train_0_8.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle(\"dataframes/full_df_cleaned_test_0_2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452521"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_unique_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 15:20:57,602 : INFO : loading Word2Vec object from models/w2v_model_epochs_5_win_5_cbow_250.model\n",
      "2019-12-18 15:20:58,275 : INFO : loading wv recursively from models/w2v_model_epochs_5_win_5_cbow_250.model.wv.* with mmap=None\n",
      "2019-12-18 15:20:58,276 : INFO : loading vectors from models/w2v_model_epochs_5_win_5_cbow_250.model.wv.vectors.npy with mmap=None\n",
      "2019-12-18 15:20:59,135 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-12-18 15:20:59,136 : INFO : loading vocabulary recursively from models/w2v_model_epochs_5_win_5_cbow_250.model.vocabulary.* with mmap=None\n",
      "2019-12-18 15:20:59,137 : INFO : loading trainables recursively from models/w2v_model_epochs_5_win_5_cbow_250.model.trainables.* with mmap=None\n",
      "2019-12-18 15:20:59,138 : INFO : loading syn1neg from models/w2v_model_epochs_5_win_5_cbow_250.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-12-18 15:20:59,978 : INFO : setting ignored attribute cum_table to None\n",
      "2019-12-18 15:20:59,978 : INFO : loaded models/w2v_model_epochs_5_win_5_cbow_250.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"models/w2v_model_epochs_5_win_5_cbow_250.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.word_vec(\"love\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(w2v_model, word_index):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "\n",
    "    ## We can assume love is always present in our vocabulary ahaha\n",
    "    embedding_matrix = np.zeros((vocab_size, w2v_model.wv.word_vec(\"love\").shape[0]))  \n",
    "    \n",
    "    for word in w2v_model.wv.vocab:\n",
    "        vector = w2v_model.wv.word_vec(word)\n",
    "        if word in word_index:\n",
    "            idx = word_index[word] \n",
    "            embedding_matrix[idx] = np.array(\n",
    "                vector, dtype=np.float32)\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(df_test.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396986"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 1810, 8634, 2884, 3383, 7]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train[0] == '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"want pottermore let ! can't obsessed let #nerdproblems\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[8634].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "def max_len(X):\n",
    "    maxlen = 0\n",
    "    for el in X:\n",
    "        maxlen = maxlen if len(el) < maxlen else len(el)\n",
    "    return maxlen\n",
    "maxlen = int(max_len(X_train)/2)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  15 1810 8634 2884 3383    7    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = create_embedding_matrix(\n",
    "    w2v_model,\n",
    "    tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895593295481452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "396986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
    "print(nonzero_elements / vocab_size)\n",
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert -1 in 0 (otherwise it doesn't work)\n",
    "y_train = np.where(df.label == 1, 1, 0)\n",
    "y_test = np.where(df_test.label == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 22, 250)           99246500  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 50)            37550     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                3060      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 99,290,831\n",
      "Trainable params: 44,331\n",
      "Non-trainable params: 99,246,500\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.8019\n",
      "Epoch 00001: val_acc improved from -inf to 0.80937, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.4142 - acc: 0.8019 - val_loss: 0.4018 - val_acc: 0.8094\n",
      "Epoch 2/40\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8129\n",
      "Epoch 00002: val_acc improved from 0.80937 to 0.81246, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3957 - acc: 0.8129 - val_loss: 0.3969 - val_acc: 0.8125\n",
      "Epoch 3/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8170\n",
      "Epoch 00003: val_acc improved from 0.81246 to 0.81330, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3888 - acc: 0.8170 - val_loss: 0.3941 - val_acc: 0.8133\n",
      "Epoch 4/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8193\n",
      "Epoch 00004: val_acc improved from 0.81330 to 0.81577, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3845 - acc: 0.8193 - val_loss: 0.3924 - val_acc: 0.8158\n",
      "Epoch 5/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8209\n",
      "Epoch 00005: val_acc improved from 0.81577 to 0.81620, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3816 - acc: 0.8209 - val_loss: 0.3897 - val_acc: 0.8162\n",
      "Epoch 6/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8222\n",
      "Epoch 00006: val_acc improved from 0.81620 to 0.81685, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3792 - acc: 0.8222 - val_loss: 0.3886 - val_acc: 0.8168\n",
      "Epoch 7/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8233\n",
      "Epoch 00007: val_acc improved from 0.81685 to 0.81689, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3771 - acc: 0.8233 - val_loss: 0.3886 - val_acc: 0.8169\n",
      "Epoch 8/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3756 - acc: 0.8244\n",
      "Epoch 00008: val_acc did not improve from 0.81689\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3756 - acc: 0.8244 - val_loss: 0.3923 - val_acc: 0.8165\n",
      "Epoch 9/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8251\n",
      "Epoch 00009: val_acc improved from 0.81689 to 0.81796, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3741 - acc: 0.8251 - val_loss: 0.3894 - val_acc: 0.8180\n",
      "Epoch 10/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.8256\n",
      "Epoch 00010: val_acc improved from 0.81796 to 0.81818, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3731 - acc: 0.8256 - val_loss: 0.3883 - val_acc: 0.8182\n",
      "Epoch 11/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8264\n",
      "Epoch 00011: val_acc improved from 0.81818 to 0.81877, saving model to models/convolutional_nn_layers_of_size_50_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3719 - acc: 0.8264 - val_loss: 0.3874 - val_acc: 0.8188\n",
      "Epoch 12/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8269\n",
      "Epoch 00012: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3711 - acc: 0.8269 - val_loss: 0.3872 - val_acc: 0.8180\n",
      "Epoch 13/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3702 - acc: 0.8274\n",
      "Epoch 00013: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3702 - acc: 0.8274 - val_loss: 0.3868 - val_acc: 0.8182\n",
      "Epoch 14/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8276\n",
      "Epoch 00014: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3695 - acc: 0.8276 - val_loss: 0.3886 - val_acc: 0.8176\n",
      "Epoch 15/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8282\n",
      "Epoch 00015: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3688 - acc: 0.8282 - val_loss: 0.3881 - val_acc: 0.8182\n",
      "Epoch 16/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3682 - acc: 0.8284\n",
      "Epoch 00016: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3682 - acc: 0.8284 - val_loss: 0.3882 - val_acc: 0.8176\n",
      "Epoch 17/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8289\n",
      "Epoch 00017: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3675 - acc: 0.8289 - val_loss: 0.3867 - val_acc: 0.8184\n",
      "Epoch 18/40\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3669 - acc: 0.8292\n",
      "Epoch 00018: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3669 - acc: 0.8292 - val_loss: 0.3878 - val_acc: 0.8183\n",
      "Epoch 19/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3665 - acc: 0.8291\n",
      "Epoch 00019: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3665 - acc: 0.8291 - val_loss: 0.3876 - val_acc: 0.8182\n",
      "Epoch 20/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.8297\n",
      "Epoch 00020: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3660 - acc: 0.8297 - val_loss: 0.3890 - val_acc: 0.8180\n",
      "Epoch 21/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8299\n",
      "Epoch 00021: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3655 - acc: 0.8299 - val_loss: 0.3898 - val_acc: 0.8172\n",
      "Epoch 22/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3651 - acc: 0.8301\n",
      "Epoch 00022: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3651 - acc: 0.8301 - val_loss: 0.3907 - val_acc: 0.8181\n",
      "Epoch 23/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8303\n",
      "Epoch 00023: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3648 - acc: 0.8302 - val_loss: 0.3890 - val_acc: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3644 - acc: 0.8305\n",
      "Epoch 00024: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3644 - acc: 0.8305 - val_loss: 0.3879 - val_acc: 0.8187\n",
      "Epoch 25/40\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8306\n",
      "Epoch 00025: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3640 - acc: 0.8306 - val_loss: 0.3901 - val_acc: 0.8184\n",
      "Epoch 26/40\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3637 - acc: 0.8308\n",
      "Epoch 00026: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3637 - acc: 0.8308 - val_loss: 0.3869 - val_acc: 0.8184\n",
      "Epoch 27/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3633 - acc: 0.8311\n",
      "Epoch 00027: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3633 - acc: 0.8311 - val_loss: 0.3915 - val_acc: 0.8167\n",
      "Epoch 28/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3631 - acc: 0.8312\n",
      "Epoch 00028: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3631 - acc: 0.8312 - val_loss: 0.3893 - val_acc: 0.8185\n",
      "Epoch 29/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3627 - acc: 0.8315\n",
      "Epoch 00029: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3627 - acc: 0.8315 - val_loss: 0.3876 - val_acc: 0.8183\n",
      "Epoch 30/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8315\n",
      "Epoch 00030: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3624 - acc: 0.8315 - val_loss: 0.3883 - val_acc: 0.8183\n",
      "Epoch 31/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8316\n",
      "Epoch 00031: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3622 - acc: 0.8316 - val_loss: 0.3903 - val_acc: 0.8176\n",
      "Epoch 32/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3620 - acc: 0.8317\n",
      "Epoch 00032: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3620 - acc: 0.8317 - val_loss: 0.3899 - val_acc: 0.8186\n",
      "Epoch 33/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.8319\n",
      "Epoch 00033: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3618 - acc: 0.8319 - val_loss: 0.3912 - val_acc: 0.8173\n",
      "Epoch 34/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3615 - acc: 0.8319\n",
      "Epoch 00034: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3615 - acc: 0.8319 - val_loss: 0.3936 - val_acc: 0.8184\n",
      "Epoch 35/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3614 - acc: 0.8321\n",
      "Epoch 00035: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3613 - acc: 0.8321 - val_loss: 0.3927 - val_acc: 0.8179\n",
      "Epoch 36/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3611 - acc: 0.8322\n",
      "Epoch 00036: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3611 - acc: 0.8322 - val_loss: 0.3883 - val_acc: 0.8183\n",
      "Epoch 37/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8322\n",
      "Epoch 00037: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3610 - acc: 0.8322 - val_loss: 0.3899 - val_acc: 0.8185\n",
      "Epoch 38/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3608 - acc: 0.8324\n",
      "Epoch 00038: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3608 - acc: 0.8324 - val_loss: 0.3933 - val_acc: 0.8182\n",
      "Epoch 39/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3606 - acc: 0.8326\n",
      "Epoch 00039: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3606 - acc: 0.8326 - val_loss: 0.3898 - val_acc: 0.8187\n",
      "Epoch 40/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8326\n",
      "Epoch 00040: val_acc did not improve from 0.81877\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3604 - acc: 0.8326 - val_loss: 0.3922 - val_acc: 0.8182\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 22, 250)           99246500  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 20, 100)           75100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 99,331,381\n",
      "Trainable params: 84,881\n",
      "Non-trainable params: 99,246,500\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8048\n",
      "Epoch 00001: val_acc improved from -inf to 0.81240, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.4093 - acc: 0.8048 - val_loss: 0.3962 - val_acc: 0.8124\n",
      "Epoch 2/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3887 - acc: 0.8171\n",
      "Epoch 00002: val_acc improved from 0.81240 to 0.81647, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3887 - acc: 0.8171 - val_loss: 0.3892 - val_acc: 0.8165\n",
      "Epoch 3/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8221\n",
      "Epoch 00003: val_acc improved from 0.81647 to 0.81885, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3798 - acc: 0.8221 - val_loss: 0.3848 - val_acc: 0.8188\n",
      "Epoch 4/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3743 - acc: 0.8252\n",
      "Epoch 00004: val_acc improved from 0.81885 to 0.81949, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3744 - acc: 0.8251 - val_loss: 0.3836 - val_acc: 0.8195\n",
      "Epoch 5/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8275\n",
      "Epoch 00005: val_acc improved from 0.81949 to 0.82026, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3701 - acc: 0.8275 - val_loss: 0.3827 - val_acc: 0.8203\n",
      "Epoch 6/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8292\n",
      "Epoch 00006: val_acc did not improve from 0.82026\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3668 - acc: 0.8292 - val_loss: 0.3848 - val_acc: 0.8192\n",
      "Epoch 7/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8308\n",
      "Epoch 00007: val_acc did not improve from 0.82026\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3641 - acc: 0.8309 - val_loss: 0.3840 - val_acc: 0.8199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.8322\n",
      "Epoch 00008: val_acc improved from 0.82026 to 0.82079, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3617 - acc: 0.8322 - val_loss: 0.3820 - val_acc: 0.8208\n",
      "Epoch 9/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8333\n",
      "Epoch 00009: val_acc improved from 0.82079 to 0.82114, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3597 - acc: 0.8333 - val_loss: 0.3818 - val_acc: 0.8211\n",
      "Epoch 10/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8345\n",
      "Epoch 00010: val_acc did not improve from 0.82114\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3579 - acc: 0.8345 - val_loss: 0.3818 - val_acc: 0.8211\n",
      "Epoch 11/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8352\n",
      "Epoch 00011: val_acc did not improve from 0.82114\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3563 - acc: 0.8352 - val_loss: 0.3863 - val_acc: 0.8202\n",
      "Epoch 12/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.8361\n",
      "Epoch 00012: val_acc improved from 0.82114 to 0.82160, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3549 - acc: 0.8361 - val_loss: 0.3829 - val_acc: 0.8216\n",
      "Epoch 13/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8369\n",
      "Epoch 00013: val_acc did not improve from 0.82160\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3536 - acc: 0.8369 - val_loss: 0.3817 - val_acc: 0.8213\n",
      "Epoch 14/40\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.8376\n",
      "Epoch 00014: val_acc improved from 0.82160 to 0.82167, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3523 - acc: 0.8376 - val_loss: 0.3836 - val_acc: 0.8217\n",
      "Epoch 15/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.8381\n",
      "Epoch 00015: val_acc did not improve from 0.82167\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3514 - acc: 0.8381 - val_loss: 0.3839 - val_acc: 0.8212\n",
      "Epoch 16/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.8386\n",
      "Epoch 00016: val_acc did not improve from 0.82167\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3503 - acc: 0.8387 - val_loss: 0.3843 - val_acc: 0.8215\n",
      "Epoch 17/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.8393\n",
      "Epoch 00017: val_acc improved from 0.82167 to 0.82212, saving model to models/convolutional_nn_layers_of_size_100_60\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3494 - acc: 0.8393 - val_loss: 0.3862 - val_acc: 0.8221\n",
      "Epoch 18/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3486 - acc: 0.8399\n",
      "Epoch 00018: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3486 - acc: 0.8399 - val_loss: 0.3854 - val_acc: 0.8207\n",
      "Epoch 19/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.8404\n",
      "Epoch 00019: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3477 - acc: 0.8404 - val_loss: 0.3867 - val_acc: 0.8216\n",
      "Epoch 20/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.8406\n",
      "Epoch 00020: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3469 - acc: 0.8406 - val_loss: 0.3888 - val_acc: 0.8196\n",
      "Epoch 21/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.8414\n",
      "Epoch 00021: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3462 - acc: 0.8414 - val_loss: 0.3873 - val_acc: 0.8218\n",
      "Epoch 22/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.8415\n",
      "Epoch 00022: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3454 - acc: 0.8415 - val_loss: 0.3890 - val_acc: 0.8200\n",
      "Epoch 23/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8418\n",
      "Epoch 00023: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 20us/sample - loss: 0.3447 - acc: 0.8418 - val_loss: 0.3897 - val_acc: 0.8200\n",
      "Epoch 24/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8425\n",
      "Epoch 00024: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3441 - acc: 0.8425 - val_loss: 0.3899 - val_acc: 0.8215\n",
      "Epoch 25/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3435 - acc: 0.8429\n",
      "Epoch 00025: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3435 - acc: 0.8429 - val_loss: 0.3860 - val_acc: 0.8214\n",
      "Epoch 26/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3429 - acc: 0.8432\n",
      "Epoch 00026: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3429 - acc: 0.8432 - val_loss: 0.3883 - val_acc: 0.8211\n",
      "Epoch 27/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8436\n",
      "Epoch 00027: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3425 - acc: 0.8436 - val_loss: 0.3870 - val_acc: 0.8214\n",
      "Epoch 28/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3420 - acc: 0.8437\n",
      "Epoch 00028: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3420 - acc: 0.8437 - val_loss: 0.3898 - val_acc: 0.8215\n",
      "Epoch 29/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.8443\n",
      "Epoch 00029: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3414 - acc: 0.8442 - val_loss: 0.3877 - val_acc: 0.8206\n",
      "Epoch 30/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3409 - acc: 0.8442\n",
      "Epoch 00030: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3409 - acc: 0.8442 - val_loss: 0.3885 - val_acc: 0.8203\n",
      "Epoch 31/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3405 - acc: 0.8447\n",
      "Epoch 00031: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3405 - acc: 0.8447 - val_loss: 0.3926 - val_acc: 0.8195\n",
      "Epoch 32/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3401 - acc: 0.8449\n",
      "Epoch 00032: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3401 - acc: 0.8449 - val_loss: 0.3901 - val_acc: 0.8206\n",
      "Epoch 33/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8451\n",
      "Epoch 00033: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3397 - acc: 0.8451 - val_loss: 0.3953 - val_acc: 0.8209\n",
      "Epoch 34/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3392 - acc: 0.8453\n",
      "Epoch 00034: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3392 - acc: 0.8453 - val_loss: 0.3934 - val_acc: 0.8206\n",
      "Epoch 35/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.8454\n",
      "Epoch 00035: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3389 - acc: 0.8454 - val_loss: 0.3974 - val_acc: 0.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8457\n",
      "Epoch 00036: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3385 - acc: 0.8457 - val_loss: 0.3960 - val_acc: 0.8171\n",
      "Epoch 37/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8459\n",
      "Epoch 00037: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3382 - acc: 0.8458 - val_loss: 0.3915 - val_acc: 0.8203\n",
      "Epoch 38/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3376 - acc: 0.8463\n",
      "Epoch 00038: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3376 - acc: 0.8463 - val_loss: 0.3944 - val_acc: 0.8199\n",
      "Epoch 39/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8463\n",
      "Epoch 00039: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3374 - acc: 0.8463 - val_loss: 0.3963 - val_acc: 0.8194\n",
      "Epoch 40/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3372 - acc: 0.8465\n",
      "Epoch 00040: val_acc did not improve from 0.82212\n",
      "2000000/2000000 [==============================] - 41s 21us/sample - loss: 0.3372 - acc: 0.8465 - val_loss: 0.3926 - val_acc: 0.8207\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 22, 250)           99246500  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 20, 150)           112650    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 60)                9060      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 99,371,931\n",
      "Trainable params: 125,431\n",
      "Non-trainable params: 99,246,500\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8057\n",
      "Epoch 00001: val_acc improved from -inf to 0.81355, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.4076 - acc: 0.8057 - val_loss: 0.3938 - val_acc: 0.8135\n",
      "Epoch 2/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8189\n",
      "Epoch 00002: val_acc improved from 0.81355 to 0.81836, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3854 - acc: 0.8189 - val_loss: 0.3859 - val_acc: 0.8184\n",
      "Epoch 3/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3755 - acc: 0.8242\n",
      "Epoch 00003: val_acc improved from 0.81836 to 0.82071, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3755 - acc: 0.8242 - val_loss: 0.3828 - val_acc: 0.8207\n",
      "Epoch 4/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8279\n",
      "Epoch 00004: val_acc improved from 0.82071 to 0.82158, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3689 - acc: 0.8279 - val_loss: 0.3803 - val_acc: 0.8216\n",
      "Epoch 5/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8306\n",
      "Epoch 00005: val_acc improved from 0.82158 to 0.82253, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3638 - acc: 0.8306 - val_loss: 0.3799 - val_acc: 0.8225\n",
      "Epoch 6/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8331\n",
      "Epoch 00006: val_acc did not improve from 0.82253\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3597 - acc: 0.8331 - val_loss: 0.3816 - val_acc: 0.8221\n",
      "Epoch 7/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.8348\n",
      "Epoch 00007: val_acc improved from 0.82253 to 0.82324, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3563 - acc: 0.8348 - val_loss: 0.3791 - val_acc: 0.8232\n",
      "Epoch 8/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8364\n",
      "Epoch 00008: val_acc did not improve from 0.82324\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3533 - acc: 0.8364 - val_loss: 0.3815 - val_acc: 0.8208\n",
      "Epoch 9/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8378\n",
      "Epoch 00009: val_acc improved from 0.82324 to 0.82362, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3508 - acc: 0.8379 - val_loss: 0.3808 - val_acc: 0.8236\n",
      "Epoch 10/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.8391\n",
      "Epoch 00010: val_acc did not improve from 0.82362\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3485 - acc: 0.8391 - val_loss: 0.3833 - val_acc: 0.8223\n",
      "Epoch 11/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8403\n",
      "Epoch 00011: val_acc did not improve from 0.82362\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3464 - acc: 0.8403 - val_loss: 0.3817 - val_acc: 0.8223\n",
      "Epoch 12/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3446 - acc: 0.8411\n",
      "Epoch 00012: val_acc did not improve from 0.82362\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3445 - acc: 0.8411 - val_loss: 0.3896 - val_acc: 0.8233\n",
      "Epoch 13/40\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3426 - acc: 0.8421\n",
      "Epoch 00013: val_acc improved from 0.82362 to 0.82397, saving model to models/convolutional_nn_layers_of_size_150_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3426 - acc: 0.8421 - val_loss: 0.3835 - val_acc: 0.8240\n",
      "Epoch 14/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8430\n",
      "Epoch 00014: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3412 - acc: 0.8430 - val_loss: 0.3899 - val_acc: 0.8216\n",
      "Epoch 15/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8439\n",
      "Epoch 00015: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3396 - acc: 0.8439 - val_loss: 0.3871 - val_acc: 0.8226\n",
      "Epoch 16/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8446\n",
      "Epoch 00016: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3383 - acc: 0.8446 - val_loss: 0.3855 - val_acc: 0.8235\n",
      "Epoch 17/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3371 - acc: 0.8453\n",
      "Epoch 00017: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3371 - acc: 0.8453 - val_loss: 0.3881 - val_acc: 0.8220\n",
      "Epoch 18/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3359 - acc: 0.8460\n",
      "Epoch 00018: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3359 - acc: 0.8460 - val_loss: 0.3844 - val_acc: 0.8226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8465\n",
      "Epoch 00019: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3348 - acc: 0.8464 - val_loss: 0.3879 - val_acc: 0.8228\n",
      "Epoch 20/40\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8471\n",
      "Epoch 00020: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3337 - acc: 0.8471 - val_loss: 0.3879 - val_acc: 0.8220\n",
      "Epoch 21/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8476\n",
      "Epoch 00021: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3326 - acc: 0.8476 - val_loss: 0.3955 - val_acc: 0.8210\n",
      "Epoch 22/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8482\n",
      "Epoch 00022: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3317 - acc: 0.8482 - val_loss: 0.3912 - val_acc: 0.8220\n",
      "Epoch 23/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3307 - acc: 0.8487\n",
      "Epoch 00023: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3307 - acc: 0.8487 - val_loss: 0.3893 - val_acc: 0.8218\n",
      "Epoch 24/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.8490\n",
      "Epoch 00024: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3301 - acc: 0.8490 - val_loss: 0.3916 - val_acc: 0.8217\n",
      "Epoch 25/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3290 - acc: 0.8497\n",
      "Epoch 00025: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3290 - acc: 0.8497 - val_loss: 0.3946 - val_acc: 0.8222\n",
      "Epoch 26/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.8502\n",
      "Epoch 00026: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3282 - acc: 0.8502 - val_loss: 0.3962 - val_acc: 0.8222\n",
      "Epoch 27/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3275 - acc: 0.8506\n",
      "Epoch 00027: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3275 - acc: 0.8506 - val_loss: 0.3957 - val_acc: 0.8213\n",
      "Epoch 28/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3267 - acc: 0.8509\n",
      "Epoch 00028: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3268 - acc: 0.8508 - val_loss: 0.3924 - val_acc: 0.8209\n",
      "Epoch 29/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.8513\n",
      "Epoch 00029: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3261 - acc: 0.8513 - val_loss: 0.3974 - val_acc: 0.8216\n",
      "Epoch 30/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.8515\n",
      "Epoch 00030: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3254 - acc: 0.8515 - val_loss: 0.4069 - val_acc: 0.8211\n",
      "Epoch 31/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3247 - acc: 0.8521\n",
      "Epoch 00031: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3247 - acc: 0.8521 - val_loss: 0.3988 - val_acc: 0.8209\n",
      "Epoch 32/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.8523\n",
      "Epoch 00032: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3243 - acc: 0.8523 - val_loss: 0.4000 - val_acc: 0.8203\n",
      "Epoch 33/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8525\n",
      "Epoch 00033: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3237 - acc: 0.8525 - val_loss: 0.3972 - val_acc: 0.8202\n",
      "Epoch 34/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.8528\n",
      "Epoch 00034: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3231 - acc: 0.8528 - val_loss: 0.4064 - val_acc: 0.8196\n",
      "Epoch 35/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3225 - acc: 0.8530\n",
      "Epoch 00035: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3225 - acc: 0.8530 - val_loss: 0.4004 - val_acc: 0.8201\n",
      "Epoch 36/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.8534\n",
      "Epoch 00036: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 45s 23us/sample - loss: 0.3221 - acc: 0.8533 - val_loss: 0.3992 - val_acc: 0.8207\n",
      "Epoch 37/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8536\n",
      "Epoch 00037: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3216 - acc: 0.8536 - val_loss: 0.4163 - val_acc: 0.8212\n",
      "Epoch 38/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3212 - acc: 0.8540\n",
      "Epoch 00038: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3212 - acc: 0.8540 - val_loss: 0.4028 - val_acc: 0.8201\n",
      "Epoch 39/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3205 - acc: 0.8544\n",
      "Epoch 00039: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3205 - acc: 0.8544 - val_loss: 0.4043 - val_acc: 0.8200\n",
      "Epoch 40/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3200 - acc: 0.8547\n",
      "Epoch 00040: val_acc did not improve from 0.82397\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3200 - acc: 0.8547 - val_loss: 0.4061 - val_acc: 0.8195\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 22, 250)           99246500  \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 20, 200)           150200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 60)                12060     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 99,412,481\n",
      "Trainable params: 165,981\n",
      "Non-trainable params: 99,246,500\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8066\n",
      "Epoch 00001: val_acc improved from -inf to 0.81515, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.4062 - acc: 0.8066 - val_loss: 0.3927 - val_acc: 0.8152\n",
      "Epoch 2/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3831 - acc: 0.8203\n",
      "Epoch 00002: val_acc improved from 0.81515 to 0.81852, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3831 - acc: 0.8203 - val_loss: 0.3847 - val_acc: 0.8185\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.8263\n",
      "Epoch 00003: val_acc improved from 0.81852 to 0.82009, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3722 - acc: 0.8263 - val_loss: 0.3825 - val_acc: 0.8201\n",
      "Epoch 4/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8305\n",
      "Epoch 00004: val_acc improved from 0.82009 to 0.82228, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3647 - acc: 0.8305 - val_loss: 0.3785 - val_acc: 0.8223\n",
      "Epoch 5/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8336\n",
      "Epoch 00005: val_acc improved from 0.82228 to 0.82343, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3588 - acc: 0.8336 - val_loss: 0.3804 - val_acc: 0.8234\n",
      "Epoch 6/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.8363\n",
      "Epoch 00006: val_acc did not improve from 0.82343\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3540 - acc: 0.8363 - val_loss: 0.3836 - val_acc: 0.8214\n",
      "Epoch 7/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3500 - acc: 0.8386\n",
      "Epoch 00007: val_acc did not improve from 0.82343\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3500 - acc: 0.8386 - val_loss: 0.3787 - val_acc: 0.8231\n",
      "Epoch 8/40\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3466 - acc: 0.8405\n",
      "Epoch 00008: val_acc did not improve from 0.82343\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3466 - acc: 0.8405 - val_loss: 0.3812 - val_acc: 0.8232\n",
      "Epoch 9/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.8424\n",
      "Epoch 00009: val_acc improved from 0.82343 to 0.82386, saving model to models/convolutional_nn_layers_of_size_200_60\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3434 - acc: 0.8424 - val_loss: 0.3801 - val_acc: 0.8239\n",
      "Epoch 10/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8438\n",
      "Epoch 00010: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3406 - acc: 0.8438 - val_loss: 0.3875 - val_acc: 0.8204\n",
      "Epoch 11/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8452\n",
      "Epoch 00011: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3381 - acc: 0.8452 - val_loss: 0.3837 - val_acc: 0.8237\n",
      "Epoch 12/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.8465\n",
      "Epoch 00012: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3358 - acc: 0.8465 - val_loss: 0.3848 - val_acc: 0.8231\n",
      "Epoch 13/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3336 - acc: 0.8478\n",
      "Epoch 00013: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3336 - acc: 0.8478 - val_loss: 0.3868 - val_acc: 0.8235\n",
      "Epoch 14/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8489\n",
      "Epoch 00014: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3317 - acc: 0.8489 - val_loss: 0.3934 - val_acc: 0.8207\n",
      "Epoch 15/40\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3299 - acc: 0.8497\n",
      "Epoch 00015: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3299 - acc: 0.8497 - val_loss: 0.3828 - val_acc: 0.8229\n",
      "Epoch 16/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8509\n",
      "Epoch 00016: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3283 - acc: 0.8509 - val_loss: 0.3846 - val_acc: 0.8227\n",
      "Epoch 17/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8518\n",
      "Epoch 00017: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3266 - acc: 0.8518 - val_loss: 0.3934 - val_acc: 0.8223\n",
      "Epoch 18/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8524\n",
      "Epoch 00018: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3251 - acc: 0.8524 - val_loss: 0.3909 - val_acc: 0.8229\n",
      "Epoch 19/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8535\n",
      "Epoch 00019: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3237 - acc: 0.8535 - val_loss: 0.4002 - val_acc: 0.8204\n",
      "Epoch 20/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.8542\n",
      "Epoch 00020: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3222 - acc: 0.8542 - val_loss: 0.3895 - val_acc: 0.8226\n",
      "Epoch 21/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8551\n",
      "Epoch 00021: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3210 - acc: 0.8551 - val_loss: 0.3986 - val_acc: 0.8230\n",
      "Epoch 22/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.8556\n",
      "Epoch 00022: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3196 - acc: 0.8556 - val_loss: 0.4031 - val_acc: 0.8225\n",
      "Epoch 23/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3184 - acc: 0.8565\n",
      "Epoch 00023: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3184 - acc: 0.8565 - val_loss: 0.3994 - val_acc: 0.8225\n",
      "Epoch 24/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8569\n",
      "Epoch 00024: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3174 - acc: 0.8569 - val_loss: 0.4102 - val_acc: 0.8219\n",
      "Epoch 25/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8578\n",
      "Epoch 00025: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3163 - acc: 0.8578 - val_loss: 0.3980 - val_acc: 0.8218\n",
      "Epoch 26/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.8582\n",
      "Epoch 00026: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3151 - acc: 0.8582 - val_loss: 0.4105 - val_acc: 0.8210\n",
      "Epoch 27/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.8586\n",
      "Epoch 00027: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3141 - acc: 0.8586 - val_loss: 0.4025 - val_acc: 0.8217\n",
      "Epoch 28/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.8592\n",
      "Epoch 00028: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3133 - acc: 0.8592 - val_loss: 0.4013 - val_acc: 0.8209\n",
      "Epoch 29/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.8598\n",
      "Epoch 00029: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3124 - acc: 0.8597 - val_loss: 0.4048 - val_acc: 0.8203\n",
      "Epoch 30/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.8601\n",
      "Epoch 00030: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3114 - acc: 0.8601 - val_loss: 0.4071 - val_acc: 0.8204\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.8607\n",
      "Epoch 00031: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3105 - acc: 0.8607 - val_loss: 0.4153 - val_acc: 0.8192\n",
      "Epoch 32/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.8613\n",
      "Epoch 00032: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3097 - acc: 0.8613 - val_loss: 0.4094 - val_acc: 0.8202\n",
      "Epoch 33/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3091 - acc: 0.8613\n",
      "Epoch 00033: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3091 - acc: 0.8613 - val_loss: 0.4164 - val_acc: 0.8200\n",
      "Epoch 34/40\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3081 - acc: 0.8620\n",
      "Epoch 00034: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3080 - acc: 0.8620 - val_loss: 0.4198 - val_acc: 0.8203\n",
      "Epoch 35/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.8622\n",
      "Epoch 00035: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3073 - acc: 0.8622 - val_loss: 0.4178 - val_acc: 0.8197\n",
      "Epoch 36/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.8628\n",
      "Epoch 00036: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 22us/sample - loss: 0.3066 - acc: 0.8628 - val_loss: 0.4132 - val_acc: 0.8200\n",
      "Epoch 37/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.8631\n",
      "Epoch 00037: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3059 - acc: 0.8631 - val_loss: 0.4128 - val_acc: 0.8193\n",
      "Epoch 38/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.8633\n",
      "Epoch 00038: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3054 - acc: 0.8633 - val_loss: 0.4229 - val_acc: 0.8196\n",
      "Epoch 39/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3046 - acc: 0.8638\n",
      "Epoch 00039: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3046 - acc: 0.8638 - val_loss: 0.4129 - val_acc: 0.8197\n",
      "Epoch 40/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8640\n",
      "Epoch 00040: val_acc did not improve from 0.82386\n",
      "2000000/2000000 [==============================] - 43s 21us/sample - loss: 0.3039 - acc: 0.8640 - val_loss: 0.4300 - val_acc: 0.8197\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 22, 250)           99246500  \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 20, 250)           187750    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 60)                15060     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 99,453,031\n",
      "Trainable params: 206,531\n",
      "Non-trainable params: 99,246,500\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/40\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8076\n",
      "Epoch 00001: val_acc improved from -inf to 0.81601, saving model to models/convolutional_nn_layers_of_size_250_60\n",
      "2000000/2000000 [==============================] - 49s 25us/sample - loss: 0.4047 - acc: 0.8076 - val_loss: 0.3894 - val_acc: 0.8160\n",
      "Epoch 2/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8212\n",
      "Epoch 00002: val_acc improved from 0.81601 to 0.81986, saving model to models/convolutional_nn_layers_of_size_250_60\n",
      "2000000/2000000 [==============================] - 47s 23us/sample - loss: 0.3813 - acc: 0.8212 - val_loss: 0.3829 - val_acc: 0.8199\n",
      "Epoch 3/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8275\n",
      "Epoch 00003: val_acc improved from 0.81986 to 0.82280, saving model to models/convolutional_nn_layers_of_size_250_60\n",
      "2000000/2000000 [==============================] - 47s 23us/sample - loss: 0.3701 - acc: 0.8275 - val_loss: 0.3783 - val_acc: 0.8228\n",
      "Epoch 4/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.8319\n",
      "Epoch 00004: val_acc improved from 0.82280 to 0.82413, saving model to models/convolutional_nn_layers_of_size_250_60\n",
      "2000000/2000000 [==============================] - 46s 23us/sample - loss: 0.3623 - acc: 0.8319 - val_loss: 0.3771 - val_acc: 0.8241\n",
      "Epoch 5/40\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3556 - acc: 0.8354\n",
      "Epoch 00005: val_acc did not improve from 0.82413\n",
      "2000000/2000000 [==============================] - 45s 23us/sample - loss: 0.3556 - acc: 0.8354 - val_loss: 0.3782 - val_acc: 0.8232\n",
      "Epoch 6/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.8384\n",
      "Epoch 00006: val_acc improved from 0.82413 to 0.82541, saving model to models/convolutional_nn_layers_of_size_250_60\n",
      "2000000/2000000 [==============================] - 47s 23us/sample - loss: 0.3503 - acc: 0.8384 - val_loss: 0.3779 - val_acc: 0.8254\n",
      "Epoch 7/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3456 - acc: 0.8411\n",
      "Epoch 00007: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3456 - acc: 0.8411 - val_loss: 0.3823 - val_acc: 0.8233\n",
      "Epoch 8/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3416 - acc: 0.8432\n",
      "Epoch 00008: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3416 - acc: 0.8432 - val_loss: 0.3808 - val_acc: 0.8239\n",
      "Epoch 9/40\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.8450\n",
      "Epoch 00009: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3380 - acc: 0.8450 - val_loss: 0.3828 - val_acc: 0.8237\n",
      "Epoch 10/40\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3347 - acc: 0.8471\n",
      "Epoch 00010: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3347 - acc: 0.8471 - val_loss: 0.3840 - val_acc: 0.8234\n",
      "Epoch 11/40\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8486\n",
      "Epoch 00011: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3317 - acc: 0.8486 - val_loss: 0.3824 - val_acc: 0.8242\n",
      "Epoch 12/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.8502\n",
      "Epoch 00012: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3289 - acc: 0.8502 - val_loss: 0.3811 - val_acc: 0.8240\n",
      "Epoch 13/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8517\n",
      "Epoch 00013: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3264 - acc: 0.8517 - val_loss: 0.3831 - val_acc: 0.8247\n",
      "Epoch 14/40\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8528\n",
      "Epoch 00014: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3242 - acc: 0.8528 - val_loss: 0.3908 - val_acc: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.8541\n",
      "Epoch 00015: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3220 - acc: 0.8541 - val_loss: 0.3870 - val_acc: 0.8232\n",
      "Epoch 16/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3199 - acc: 0.8553\n",
      "Epoch 00016: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3199 - acc: 0.8553 - val_loss: 0.3896 - val_acc: 0.8234\n",
      "Epoch 17/40\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.8565\n",
      "Epoch 00017: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3179 - acc: 0.8565 - val_loss: 0.3945 - val_acc: 0.8233\n",
      "Epoch 18/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8575\n",
      "Epoch 00018: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3160 - acc: 0.8575 - val_loss: 0.3879 - val_acc: 0.8229\n",
      "Epoch 19/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3143 - acc: 0.8585\n",
      "Epoch 00019: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3143 - acc: 0.8585 - val_loss: 0.3943 - val_acc: 0.8217\n",
      "Epoch 20/40\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.8595\n",
      "Epoch 00020: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3127 - acc: 0.8595 - val_loss: 0.4007 - val_acc: 0.8224\n",
      "Epoch 21/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.8603\n",
      "Epoch 00021: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3111 - acc: 0.8603 - val_loss: 0.4035 - val_acc: 0.8221\n",
      "Epoch 22/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3096 - acc: 0.8613\n",
      "Epoch 00022: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3096 - acc: 0.8613 - val_loss: 0.4034 - val_acc: 0.8209\n",
      "Epoch 23/40\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.8619\n",
      "Epoch 00023: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3082 - acc: 0.8619 - val_loss: 0.4035 - val_acc: 0.8217\n",
      "Epoch 24/40\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.8628\n",
      "Epoch 00024: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 42s 21us/sample - loss: 0.3068 - acc: 0.8628 - val_loss: 0.4088 - val_acc: 0.8217\n",
      "Epoch 25/40\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.8636\n",
      "Epoch 00025: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 50s 25us/sample - loss: 0.3055 - acc: 0.8636 - val_loss: 0.4033 - val_acc: 0.8218\n",
      "Epoch 26/40\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8641\n",
      "Epoch 00026: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 49s 25us/sample - loss: 0.3044 - acc: 0.8641 - val_loss: 0.4032 - val_acc: 0.8212\n",
      "Epoch 27/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8648\n",
      "Epoch 00027: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3033 - acc: 0.8648 - val_loss: 0.4127 - val_acc: 0.8209\n",
      "Epoch 28/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.8657\n",
      "Epoch 00028: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3021 - acc: 0.8657 - val_loss: 0.4095 - val_acc: 0.8212\n",
      "Epoch 29/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3010 - acc: 0.8661\n",
      "Epoch 00029: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3010 - acc: 0.8661 - val_loss: 0.4202 - val_acc: 0.8204\n",
      "Epoch 30/40\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.8666\n",
      "Epoch 00030: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.3001 - acc: 0.8667 - val_loss: 0.4167 - val_acc: 0.8195\n",
      "Epoch 31/40\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.8675\n",
      "Epoch 00031: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2989 - acc: 0.8675 - val_loss: 0.4251 - val_acc: 0.8199\n",
      "Epoch 32/40\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8680\n",
      "Epoch 00032: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2980 - acc: 0.8680 - val_loss: 0.4162 - val_acc: 0.8199\n",
      "Epoch 33/40\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.8684\n",
      "Epoch 00033: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2973 - acc: 0.8684 - val_loss: 0.4135 - val_acc: 0.8199\n",
      "Epoch 34/40\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.8692\n",
      "Epoch 00034: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2961 - acc: 0.8692 - val_loss: 0.4170 - val_acc: 0.8192\n",
      "Epoch 35/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.8697\n",
      "Epoch 00035: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2951 - acc: 0.8697 - val_loss: 0.4291 - val_acc: 0.8181\n",
      "Epoch 36/40\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.8702\n",
      "Epoch 00036: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2943 - acc: 0.8702 - val_loss: 0.4232 - val_acc: 0.8198\n",
      "Epoch 37/40\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.8706\n",
      "Epoch 00037: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2934 - acc: 0.8706 - val_loss: 0.4416 - val_acc: 0.8189\n",
      "Epoch 38/40\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.8711\n",
      "Epoch 00038: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2926 - acc: 0.8711 - val_loss: 0.4238 - val_acc: 0.8194\n",
      "Epoch 39/40\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.8716\n",
      "Epoch 00039: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2917 - acc: 0.8716 - val_loss: 0.4312 - val_acc: 0.8186\n",
      "Epoch 40/40\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8720\n",
      "Epoch 00040: val_acc did not improve from 0.82541\n",
      "2000000/2000000 [==============================] - 40s 20us/sample - loss: 0.2911 - acc: 0.8720 - val_loss: 0.4259 - val_acc: 0.8166\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 251, 50):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim,\n",
    "                               input_length=maxlen,\n",
    "                               weights=[embedding_matrix],\n",
    "                               trainable=False))\n",
    "    model.add(layers.Conv1D(i, 3, activation='relu'))   ## Maybe I should increase the kernel window (currently only 5)\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    filepath=\"models/convolutional_nn_layers_of_size_{}_{}\".format(i, 60)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=40,\n",
    "                        verbose=True,\n",
    "                        callbacks=callbacks_list,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8064\n",
      "Epoch 00001: val_acc improved from -inf to 0.81485, saving model to models/convolutional_nn_layers_of_size_256_30\n",
      "2000000/2000000 [==============================] - 1566s 783us/sample - loss: 0.4058 - acc: 0.8064 - val_loss: 0.3916 - val_acc: 0.8148\n",
      "Epoch 2/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8225\n",
      "Epoch 00002: val_acc improved from 0.81485 to 0.81871, saving model to models/convolutional_nn_layers_of_size_256_30\n",
      "2000000/2000000 [==============================] - 1586s 793us/sample - loss: 0.3780 - acc: 0.8225 - val_loss: 0.3842 - val_acc: 0.8187\n",
      "Epoch 3/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8328\n",
      "Epoch 00003: val_acc improved from 0.81871 to 0.81954, saving model to models/convolutional_nn_layers_of_size_256_30\n",
      "2000000/2000000 [==============================] - 1629s 814us/sample - loss: 0.3597 - acc: 0.8328 - val_loss: 0.3835 - val_acc: 0.8195\n",
      "Epoch 4/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3432 - acc: 0.8416\n",
      "Epoch 00004: val_acc did not improve from 0.81954\n",
      "2000000/2000000 [==============================] - 1662s 831us/sample - loss: 0.3432 - acc: 0.8416 - val_loss: 0.3895 - val_acc: 0.8174\n",
      "Epoch 5/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8496\n",
      "Epoch 00005: val_acc did not improve from 0.81954\n",
      "2000000/2000000 [==============================] - 1664s 832us/sample - loss: 0.3286 - acc: 0.8496 - val_loss: 0.3938 - val_acc: 0.8189\n",
      "Epoch 6/10\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8565\n",
      "Epoch 00006: val_acc did not improve from 0.81954\n",
      "2000000/2000000 [==============================] - 1665s 833us/sample - loss: 0.3157 - acc: 0.8565 - val_loss: 0.4155 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      " 576768/2000000 [=======>......................] - ETA: 18:50 - loss: 0.2972 - acc: 0.8663"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d28ddee54cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     batch_size=128)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath=\"models/convolutional_nn_layers_of_size_{}_{}\".format(256, 30)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### don't add this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 44, 200)           79397200  \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                6030      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 79,403,261\n",
      "Trainable params: 79,403,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/30\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8114\n",
      "Epoch 00001: val_acc improved from -inf to 0.82468, saving model to models/random_nn_layers_of_size_30_big\n",
      "2000000/2000000 [==============================] - 1074s 537us/sample - loss: 0.3982 - acc: 0.8114 - val_loss: 0.3758 - val_acc: 0.8247\n",
      "Epoch 2/30\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3439 - acc: 0.8432\n",
      "Epoch 00002: val_acc improved from 0.82468 to 0.82823, saving model to models/random_nn_layers_of_size_30_big\n",
      "2000000/2000000 [==============================] - 1078s 539us/sample - loss: 0.3439 - acc: 0.8432 - val_loss: 0.3695 - val_acc: 0.8282\n",
      "Epoch 3/30\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.8632\n",
      "Epoch 00003: val_acc did not improve from 0.82823\n",
      "2000000/2000000 [==============================] - 1074s 537us/sample - loss: 0.3073 - acc: 0.8632 - val_loss: 0.3769 - val_acc: 0.8282\n",
      "Epoch 4/30\n",
      " 688640/2000000 [=========>....................] - ETA: 11:42 - loss: 0.2711 - acc: 0.8815"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7947b0a29474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         batch_size=128)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(30, 101, 10):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                               weights=[embedding_matrix], \n",
    "                               input_length=maxlen, \n",
    "                               trainable=False))\n",
    "    model.add(layers.GlobalMaxPool1D())\n",
    "    model.add(layers.Dense(i, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    filepath=\"models/random_nn_layers_of_size_{}_big\".format(i)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=30,\n",
    "                        verbose=True,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=callbacks_list,\n",
    "                        batch_size=128)\n",
    "    loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "    print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "    print(\"#############################\\n############################\\n##################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
