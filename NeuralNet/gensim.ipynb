{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import smart_open\n",
    "import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../Data/train_pos.txt\"\n",
    "test_file = \"../Data/test_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train_file))\n",
    "test_corpus = list(read_corpus(test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['user', 'dunno', 'justin', 'read', 'my', 'mention', 'or', 'not', 'only', 'justin', 'and', 'god', 'knows', 'about', 'that', 'but', 'hope', 'you', 'will', 'follow', 'me', 'believe'], tags=[0]), TaggedDocument(words=['because', 'your', 'logic', 'is', 'so', 'dumb', 'won', 'even', 'crop', 'out', 'your', 'name', 'or', 'your', 'photo', 'tsk', 'url'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19326"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20487756,  0.08899808, -0.0681494 ,  0.12627402,  0.04539736,\n",
       "        0.00123082, -0.1307659 ,  0.16447656, -0.01045008,  0.14504078,\n",
       "       -0.0656509 , -0.20671836,  0.09884079, -0.12041245,  0.05194834,\n",
       "        0.08882205, -0.05043878,  0.1711762 , -0.16186517,  0.3403733 ,\n",
       "        0.06447627,  0.13376349, -0.1303575 ,  0.1683445 ,  0.19058312,\n",
       "        0.07654331,  0.03617232, -0.10046463, -0.06874552,  0.01534981,\n",
       "        0.20827037,  0.09971488, -0.00719216, -0.3770539 ,  0.01683249,\n",
       "        0.05633703,  0.05866466,  0.04396249,  0.07770579,  0.01865072,\n",
       "        0.15823819, -0.07933328, -0.07400562,  0.16164783,  0.03261593,\n",
       "        0.18935075,  0.03030867, -0.08947752,  0.07227089,  0.15786079],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector([\"hello\", \"i'm\", \"fine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c52d48bbe1745b9a8b32c619310f6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|â–Ž         | 2586/100000 [00:26<06:33, 247.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in tqdm(range(len(train_corpus))):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=10)\n",
    "    try:\n",
    "        rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    except ValueError:\n",
    "        rank = 11 \n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 77658, 11: 13292, 1: 3895, 2: 1611, 3: 937, 4: 687, 5: 519, 6: 413, 7: 387, 8: 334, 9: 267})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# See how well are we fitting the input data.\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'aw', 'ino', 'need', 'to', 'be', 'back', 'soon', 'haha', 'but', 'still', 'love', 'it', 'despite', 'the', 'dodgy', 'acting', 'and', 'gabriella', 'uh', 'ha', 'aw', 'wish', 'could', 'sing', 'xx']\n",
      "(54394, 0.6134401559829712)\n",
      "['user', 'lol', 'must', 'admit', 'do', 'use', 'that', 'sometimes', 'but', 'not', 'that', 'often', 'hope']\n"
     ]
    }
   ],
   "source": [
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=1)\n",
    "\n",
    "print(test_corpus[doc_id])\n",
    "print(sims[0])\n",
    "print(train_corpus[sims[0][0]].words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
