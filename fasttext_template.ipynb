{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_helpers import *\n",
    "\n",
    "take_full = True\n",
    "test_locally = False\n",
    "create_new_text_files = True\n",
    "\n",
    "# Specify here what cleaning functions you want to use\n",
    "cleaning_options = ['clean_new_line', 'remove_stopwords', 'clean_tags',\n",
    "                    'clean_punctuation', 'remove_numbers', 'lemmatize']\n",
    "\n",
    "\n",
    "clean = {\n",
    "    \"clean_new_line\": clean_new_line,\n",
    "    \"lowercase\": lowercase,\n",
    "    \"lemmatize\": lemmatize,\n",
    "    \"remove_stopwords\": remove_stopwords,\n",
    "    \"translate\": perform_translation,\n",
    "    \"clean_punctuation\": clean_punctuation,\n",
    "    \"clean_tags\" : clean_tags,\n",
    "    \"remove_numbers\": remove_numbers,\n",
    "}\n",
    "\n",
    "\n",
    "# algorithm_used = \"\"\n",
    "# algorithm = {\n",
    "#     \"naive_bayes\": ,\n",
    "#     \"logistic_regression\": ,\n",
    "#     \"svm\": ,\n",
    "#     \"lstm\":,\n",
    "#     \"fasttext\":,\n",
    "#     \"cnn\": ,\n",
    "# }\n",
    "\n",
    "# options = []\n",
    "# additional_options = {\n",
    "#     \"count_frequency\": ,\n",
    "#     \"count_ngrams\": ,\n",
    "    \n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_pos = 'Data/train_pos.txt'\n",
    "if take_full:\n",
    "    input_file_pos = 'Data/train_pos_full.txt'\n",
    "  \n",
    "input_file_neg = 'Data/train_neg.txt'\n",
    "if take_full:\n",
    "    input_file_neg = 'Data/train_neg_full.txt'\n",
    "    \n",
    "list_of_pos_sentences = []\n",
    "with open(input_file_pos, 'r') as f:\n",
    "    for line in f:\n",
    "        list_of_pos_sentences.append(line)\n",
    " \n",
    "list_of_neg_sentences = []\n",
    "with open(input_file_neg, 'r') as f:\n",
    "    for line in f:\n",
    "        list_of_neg_sentences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handling import build_sentences\n",
    "\n",
    "df = build_sentences(list_of_pos_sentences, list_of_neg_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentence.apply(lambda x: len(x.split(\"\\n\"))) > 2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 79.5 ms, total: 3.43 s\n",
      "Wall time: 3.43 s\n",
      "clean_new_line\n",
      "                                            sentence  label\n",
      "0  <user> i dunno justin read my mention or not ....      1\n",
      "1  because your logic is so dumb , i won't even c...      1\n",
      "2  \" <user> just put casper in a box ! \" looved t...      1\n",
      "3  <user> <user> thanks sir > > don't trip lil ma...      1\n",
      "4  visiting my brother tmr is the bestest birthda...      1\n",
      "0\n",
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "################################\n",
      "\n",
      "\n",
      "CPU times: user 7.61 s, sys: 141 ms, total: 7.75 s\n",
      "Wall time: 7.77 s\n",
      "remove_stopwords\n",
      "                                            sentence  label\n",
      "0  <user> dunno justin read mention . justin god ...      1\n",
      "1    logic dumb , even crop name photo . tsk . <url>      1\n",
      "2  \" <user> put casper box ! \" looved battle ! #c...      1\n",
      "3  <user> <user> thanks sir > > trip lil mama ......      1\n",
      "4  visiting brother tmr bestest birthday gift eve...      1\n",
      "0\n",
      "logic dumb , even crop name photo . tsk . <url>\n",
      "################################\n",
      "\n",
      "\n",
      "CPU times: user 21.7 s, sys: 125 ms, total: 21.9 s\n",
      "Wall time: 21.9 s\n",
      "clean_tags\n",
      "                                            sentence  label\n",
      "0  dunno justin read mention . justin god knows ,...      1\n",
      "1          logic dumb , even crop name photo . tsk .      1\n",
      "2   \" put casper box ! \" looved battle ! #crakkbitch      1\n",
      "3  thanks sir > > trip lil mama ... keep doin ya ...      1\n",
      "4  visiting brother tmr bestest birthday gift eve...      1\n",
      "0\n",
      "logic dumb , even crop name photo . tsk .\n",
      "################################\n",
      "\n",
      "\n",
      "CPU times: user 5.29 s, sys: 3.96 ms, total: 5.3 s\n",
      "Wall time: 5.29 s\n",
      "clean_punctuation\n",
      "                                            sentence  label\n",
      "0  dunno justin read mention justin god knows hop...      1\n",
      "1                logic dumb even crop name photo tsk      1\n",
      "2       put casper box ! looved battle ! #crakkbitch      1\n",
      "3  thanks sir trip lil mama ... keep doin ya thang !      1\n",
      "4  visiting brother tmr bestest birthday gift eve...      1\n",
      "0\n",
      "logic dumb even crop name photo tsk\n",
      "################################\n",
      "\n",
      "\n",
      "CPU times: user 8.13 s, sys: 0 ns, total: 8.13 s\n",
      "Wall time: 8.14 s\n",
      "remove_numbers\n",
      "                                            sentence  label\n",
      "0  dunno justin read mention justin god knows hop...      1\n",
      "1                logic dumb even crop name photo tsk      1\n",
      "2       put casper box ! looved battle ! #crakkbitch      1\n",
      "3   thanks sir trip lil mama .. keep doin ya thang !      1\n",
      "4  visiting brother tmr bestest birthday gift eve...      1\n",
      "0\n",
      "logic dumb even crop name photo tsk\n",
      "################################\n",
      "\n",
      "\n",
      "CPU times: user 1min 23s, sys: 304 ms, total: 1min 23s\n",
      "Wall time: 1min 24s\n",
      "lemmatize\n",
      "                                            sentence  label\n",
      "0  dunno justin read mention justin god know hope...      1\n",
      "1                logic dumb even crop name photo tsk      1\n",
      "2       put casper box ! looved battle ! #crakkbitch      1\n",
      "3   thanks sir trip lil mama .. keep doin ya thang !      1\n",
      "4  visiting brother tmr bestest birthday gift eve...      1\n",
      "0\n",
      "logic dumb even crop name photo tsk\n",
      "################################\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dunno justin read mention justin god know hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>logic dumb even crop name photo tsk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>put casper box ! looved battle ! #crakkbitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>thanks sir trip lil mama .. keep doin ya thang !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>visiting brother tmr bestest birthday gift eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  dunno justin read mention justin god know hope...      1\n",
       "1                logic dumb even crop name photo tsk      1\n",
       "2       put casper box ! looved battle ! #crakkbitch      1\n",
       "3   thanks sir trip lil mama .. keep doin ya thang !      1\n",
       "4  visiting brother tmr bestest birthday gift eve...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform all the cleaning options selected\n",
    "\n",
    "for clean_option in cleaning_options:\n",
    "    counter_of_occurrences = 0\n",
    "    %time df = clean[clean_option](df)\n",
    "    print(clean_option)\n",
    "    print(df.head())\n",
    "    print(df.iloc[1].sentence)\n",
    "    print(\"################################\\n\\n\")\n",
    "    \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence    2500000\n",
      "label       2500000\n",
      "dtype: int64\n",
      "sentence    1250000\n",
      "label       1250000\n",
      "dtype: int64\n",
      "sentence    1250000\n",
      "label       1250000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print counter of sentence per each label\n",
    "print(df.count())\n",
    "print(df[df.label == -1].count())\n",
    "print(df[df.label ==  1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559208"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import count_unique_words, count_unique_ngrams\n",
    "\n",
    "count_unique_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10820863"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import count_unique_words\n",
    "\n",
    "count_unique_ngrams(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext    # library to do sentence representation\n",
    "from helpers import create_labelled_file\n",
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1b3c0da91840e1a070285ee4fb0237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 15min 26s, sys: 1.67 s, total: 15min 28s\n",
      "Wall time: 15min 29s\n"
     ]
    }
   ],
   "source": [
    "if test_locally:\n",
    "    %%time\n",
    "    if create_new_text_files:\n",
    "        # create k-fold\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "        iter_n = 0\n",
    "        for train_index, test_index in tqdm(kf.split(df)):\n",
    "            # create test and train for the k-fold cross validation\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            train_file = create_labelled_file(\"cross_val/train_fasttext_{}.txt\".format(iter_n), train)\n",
    "            test_file = create_labelled_file(\"cross_val/test_fasttext_{}.txt\".format(iter_n), test)\n",
    "            iter_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382111485e92426f87bb2815066de6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8019456\n",
      "0.8067740000000001\n",
      "0.8019444\n",
      "0.80184\n",
      "0.8046327999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_locally:\n",
    "    df_precisions = {}\n",
    "    for epochs in tqdm(range(10, 20, 2)):\n",
    "        precisions = []\n",
    "        for k in range(k_folds):\n",
    "            model = fasttext.train_supervised(\"cross_val/train_fasttext_{}.txt\".format(k), epoch=epochs, loss='hs')\n",
    "            results = model.test(\"cross_val/test_fasttext_{}.txt\".format(k))\n",
    "            precisions.append(results[1])   # results is a tuple with number of predictions, precision and recall\n",
    "            # in our case both the precision and the recall are the same (there is only one possible label)\n",
    "        df_precisions[epochs] = precisions\n",
    "        print(np.array(precisions).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff41538f090>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_precisions = pd.DataFrame(df_precisions)\n",
    "df_precisions.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_locally:\n",
    "    # Write the entire dataset as trainig\n",
    "    train_file = create_labelled_file(\"cross_val/train_fasttext_full.txt\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must find the correct epochs star using cross validation!\n",
    "if not test_locally:\n",
    "    epochs_star = 25\n",
    "    %time model = fasttext.train_supervised(\"cross_val/train_fasttext_full.txt\", epoch=epochs_star, loss='hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_locally:\n",
    "    # We have to get the test dataset and clean it as we have done with the training dataset\n",
    "    df_test = []\n",
    "    with open(\"Data/test_data.txt\", 'r') as f:\n",
    "        for l in f:\n",
    "            id_ = l.split(\",\")[0]\n",
    "            # it is a csv, but you have to keep other commas (only the first one is relevant)\n",
    "            sentence = \",\".join(l.split(\",\")[1:])\n",
    "            df_test.append({\n",
    "                \"label\": int(id_),\n",
    "                \"sentence\": sentence\n",
    "            })\n",
    "    df_test = pd.DataFrame(df_test)\n",
    "    df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_new_line\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter ( sports with the port...      1\n",
      "1  <user> shucks well i work all week so now i ca...      2\n",
      "2            i cant stay away from bug thats my baby      3\n",
      "3  <user> no ma'am ! ! ! lol im perfectly fine an...      4\n",
      "4  whenever i fall asleep watching the tv , i alw...      5\n",
      "################################\n",
      "\n",
      "\n",
      "remove_stopwords\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter ( sports portable sea-...      1\n",
      "1  <user> shucks well work week can't come cheer ...      2\n",
      "2                      cant stay away bug thats baby      3\n",
      "3  <user> ma'am ! ! ! lol im perfectly fine conta...      4\n",
      "4  whenever fall asleep watching tv , always wake...      5\n",
      "################################\n",
      "\n",
      "\n",
      "clean_tags\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter ( sports portable sea-...      1\n",
      "1  shucks well work week can't come cheer ! oh pu...      2\n",
      "2                      cant stay away bug thats baby      3\n",
      "3  ma'am ! ! ! lol im perfectly fine contagious a...      4\n",
      "4  whenever fall asleep watching tv , always wake...      5\n",
      "################################\n",
      "\n",
      "\n",
      "clean_punctuation\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter sports portable sea-do...      1\n",
      "1  shucks well work week can't come cheer ! oh pu...      2\n",
      "2                      cant stay away bug thats baby      3\n",
      "3  ma'am ! ! ! lol im perfectly fine contagious a...      4\n",
      "4  whenever fall asleep watching tv always wake h...      5\n",
      "################################\n",
      "\n",
      "\n",
      "remove_numbers\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter sports portable sea-do...      1\n",
      "1  shucks well work week can't come cheer ! oh pu...      2\n",
      "2                      cant stay away bug thats baby      3\n",
      "3  ma'am ! ! ! lol im perfectly fine contagious a...      4\n",
      "4  whenever fall asleep watching tv always wake h...      5\n",
      "################################\n",
      "\n",
      "\n",
      "lemmatize\n",
      "                                            sentence  label\n",
      "0  sea doo pro sea scooter sport portable sea-doo...      1\n",
      "1  shuck well work week can't come cheer ! oh put...      2\n",
      "2                      cant stay away bug thats baby      3\n",
      "3  ma'am ! ! ! lol im perfectly fine contagious a...      4\n",
      "4  whenever fall asleep watching tv always wake h...      5\n",
      "################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not test_locally:\n",
    "    for clean_option in cleaning_options:\n",
    "        df_test = clean[clean_option](df_test)\n",
    "        print(clean_option)\n",
    "        print(df_test.head())\n",
    "        print(\"################################\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_locally:\n",
    "    # The label follows the wildcard __label__\n",
    "    series_predictions = df_test.sentence.apply(lambda x: model.predict(x)[0][0].split(\"__label__\")[1])\n",
    "    results = pd.DataFrame({\n",
    "        \"Id\": df_test['label'],\n",
    "        \"Prediction\": series_predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Prediction\n",
       "0   1         -1\n",
       "1   2         -1\n",
       "2   3         -1\n",
       "3   4          1\n",
       "4   5         -1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning] *",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
