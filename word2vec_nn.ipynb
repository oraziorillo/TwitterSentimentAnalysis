{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from helpers import count_unique_words, count_unique_ngrams, \\\n",
    "            build_unique_ngrams, create_sentence_vectors, create_sentence_vectors_submission\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import gensim   # Not sure whether it is better to use gensim or tensorflow :/\n",
    "import logging\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    " \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-14 19:48:09,981 : INFO : loading Word2Vec object from models/w2v_model_epochs_5_win_5_sg_200.model\n",
      "2019-12-14 19:48:10,667 : INFO : loading wv recursively from models/w2v_model_epochs_5_win_5_sg_200.model.wv.* with mmap=None\n",
      "2019-12-14 19:48:10,667 : INFO : loading vectors from models/w2v_model_epochs_5_win_5_sg_200.model.wv.vectors.npy with mmap=None\n",
      "2019-12-14 19:48:10,785 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-12-14 19:48:10,786 : INFO : loading vocabulary recursively from models/w2v_model_epochs_5_win_5_sg_200.model.vocabulary.* with mmap=None\n",
      "2019-12-14 19:48:10,786 : INFO : loading trainables recursively from models/w2v_model_epochs_5_win_5_sg_200.model.trainables.* with mmap=None\n",
      "2019-12-14 19:48:10,786 : INFO : loading syn1neg from models/w2v_model_epochs_5_win_5_sg_200.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-12-14 19:48:11,486 : INFO : setting ignored attribute cum_table to None\n",
      "2019-12-14 19:48:11,487 : INFO : loaded models/w2v_model_epochs_5_win_5_sg_200.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"models/w2v_model_epochs_5_win_5_sg_200.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-14 19:48:13,618 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('minivan', 0.6979140043258667),\n",
       " ('dealership', 0.6960715055465698),\n",
       " ('towed', 0.6671639680862427),\n",
       " ('roundabout', 0.6555763483047485),\n",
       " ('prius', 0.6434677839279175),\n",
       " ('serviced', 0.643191933631897),\n",
       " ('acaliyte', 0.6357315182685852),\n",
       " ('swerved', 0.6350514888763428),\n",
       " ('1v1', 0.6341693997383118),\n",
       " ('mot', 0.6275011301040649)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_size = w2v_model.wv.vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is unfortunately very high memory consumptive\n",
    "\n",
    "sentence_train_x = np.load(\"np_arrays/sentences_train_x_0_8.npy\")\n",
    "sentence_train_y = np.load(\"np_arrays/sentences_train_y_0_8.npy\")\n",
    "\n",
    "sentence_test_x = np.load(\"np_arrays/sentences_test_x_0_2.npy\")\n",
    "sentence_test_y = np.load(\"np_arrays/sentences_test_y_0_2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting with number of layers: 15\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.4346 - acc: 0.7904\n",
      "Epoch 00001: val_acc improved from -inf to 0.79772, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 29s 14us/sample - loss: 0.4346 - acc: 0.7904 - val_loss: 0.4231 - val_acc: 0.7977\n",
      "Epoch 2/20\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.4211 - acc: 0.7984\n",
      "Epoch 00002: val_acc improved from 0.79772 to 0.79917, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4211 - acc: 0.7985 - val_loss: 0.4201 - val_acc: 0.7992\n",
      "Epoch 3/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.4175 - acc: 0.8006\n",
      "Epoch 00003: val_acc improved from 0.79917 to 0.79970, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4175 - acc: 0.8006 - val_loss: 0.4181 - val_acc: 0.7997\n",
      "Epoch 4/20\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8017\n",
      "Epoch 00004: val_acc improved from 0.79970 to 0.80184, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4155 - acc: 0.8017 - val_loss: 0.4147 - val_acc: 0.8018\n",
      "Epoch 5/20\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8023\n",
      "Epoch 00005: val_acc improved from 0.80184 to 0.80218, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 29s 14us/sample - loss: 0.4143 - acc: 0.8023 - val_loss: 0.4143 - val_acc: 0.8022\n",
      "Epoch 6/20\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.4134 - acc: 0.8030\n",
      "Epoch 00006: val_acc did not improve from 0.80218\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4133 - acc: 0.8030 - val_loss: 0.4178 - val_acc: 0.8002\n",
      "Epoch 7/20\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8032\n",
      "Epoch 00007: val_acc did not improve from 0.80218\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4125 - acc: 0.8032 - val_loss: 0.4145 - val_acc: 0.8016\n",
      "Epoch 8/20\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8037\n",
      "Epoch 00008: val_acc improved from 0.80218 to 0.80338, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4119 - acc: 0.8037 - val_loss: 0.4128 - val_acc: 0.8034\n",
      "Epoch 9/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8040\n",
      "Epoch 00009: val_acc did not improve from 0.80338\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4113 - acc: 0.8040 - val_loss: 0.4130 - val_acc: 0.8025\n",
      "Epoch 10/20\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8042\n",
      "Epoch 00010: val_acc did not improve from 0.80338\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4109 - acc: 0.8042 - val_loss: 0.4138 - val_acc: 0.8016\n",
      "Epoch 11/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8045\n",
      "Epoch 00011: val_acc did not improve from 0.80338\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4105 - acc: 0.8045 - val_loss: 0.4115 - val_acc: 0.8032\n",
      "Epoch 12/20\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8049\n",
      "Epoch 00012: val_acc did not improve from 0.80338\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4101 - acc: 0.8049 - val_loss: 0.4118 - val_acc: 0.8027\n",
      "Epoch 13/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8049\n",
      "Epoch 00013: val_acc did not improve from 0.80338\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4098 - acc: 0.8050 - val_loss: 0.4137 - val_acc: 0.8018\n",
      "Epoch 14/20\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8052\n",
      "Epoch 00014: val_acc improved from 0.80338 to 0.80420, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4094 - acc: 0.8052 - val_loss: 0.4106 - val_acc: 0.8042\n",
      "Epoch 15/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8053\n",
      "Epoch 00015: val_acc improved from 0.80420 to 0.80460, saving model to models/weights_2_layers_15_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4091 - acc: 0.8053 - val_loss: 0.4107 - val_acc: 0.8046\n",
      "Epoch 16/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8054\n",
      "Epoch 00016: val_acc did not improve from 0.80460\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4090 - acc: 0.8054 - val_loss: 0.4102 - val_acc: 0.8039\n",
      "Epoch 17/20\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.4088 - acc: 0.8056\n",
      "Epoch 00017: val_acc did not improve from 0.80460\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4088 - acc: 0.8056 - val_loss: 0.4135 - val_acc: 0.8030\n",
      "Epoch 18/20\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.4086 - acc: 0.8056\n",
      "Epoch 00018: val_acc did not improve from 0.80460\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4086 - acc: 0.8056 - val_loss: 0.4110 - val_acc: 0.8036\n",
      "Epoch 19/20\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8057\n",
      "Epoch 00019: val_acc did not improve from 0.80460\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4085 - acc: 0.8057 - val_loss: 0.4104 - val_acc: 0.8042\n",
      "Epoch 20/20\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.4082 - acc: 0.8057\n",
      "Epoch 00020: val_acc did not improve from 0.80460\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4082 - acc: 0.8057 - val_loss: 0.4110 - val_acc: 0.8033\n",
      "\n",
      "\n",
      "Starting with number of layers: 20\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.4320 - acc: 0.7917\n",
      "Epoch 00001: val_acc improved from -inf to 0.79916, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4320 - acc: 0.7917 - val_loss: 0.4191 - val_acc: 0.7992\n",
      "Epoch 2/20\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.8002\n",
      "Epoch 00002: val_acc improved from 0.79916 to 0.80259, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4172 - acc: 0.8002 - val_loss: 0.4136 - val_acc: 0.8026\n",
      "Epoch 3/20\n",
      "1996288/2000000 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8028\n",
      "Epoch 00003: val_acc improved from 0.80259 to 0.80357, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 29s 14us/sample - loss: 0.4130 - acc: 0.8028 - val_loss: 0.4118 - val_acc: 0.8036\n",
      "Epoch 4/20\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8043\n",
      "Epoch 00004: val_acc improved from 0.80357 to 0.80374, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4107 - acc: 0.8043 - val_loss: 0.4112 - val_acc: 0.8037\n",
      "Epoch 5/20\n",
      "1996288/2000000 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8052\n",
      "Epoch 00005: val_acc did not improve from 0.80374\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4093 - acc: 0.8052 - val_loss: 0.4126 - val_acc: 0.8034\n",
      "Epoch 6/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8058\n",
      "Epoch 00006: val_acc did not improve from 0.80374\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4081 - acc: 0.8058 - val_loss: 0.4166 - val_acc: 0.7997\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.4073 - acc: 0.8063\n",
      "Epoch 00007: val_acc improved from 0.80374 to 0.80620, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 27s 14us/sample - loss: 0.4073 - acc: 0.8063 - val_loss: 0.4085 - val_acc: 0.8062\n",
      "Epoch 8/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8065\n",
      "Epoch 00008: val_acc did not improve from 0.80620\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4066 - acc: 0.8065 - val_loss: 0.4088 - val_acc: 0.8055\n",
      "Epoch 9/20\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.8069\n",
      "Epoch 00009: val_acc improved from 0.80620 to 0.80628, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4060 - acc: 0.8069 - val_loss: 0.4073 - val_acc: 0.8063\n",
      "Epoch 10/20\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.4056 - acc: 0.8072\n",
      "Epoch 00010: val_acc improved from 0.80628 to 0.80649, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4056 - acc: 0.8072 - val_loss: 0.4067 - val_acc: 0.8065\n",
      "Epoch 11/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.4051 - acc: 0.8074\n",
      "Epoch 00011: val_acc improved from 0.80649 to 0.80658, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4051 - acc: 0.8074 - val_loss: 0.4065 - val_acc: 0.8066\n",
      "Epoch 12/20\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8075\n",
      "Epoch 00012: val_acc improved from 0.80658 to 0.80659, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4048 - acc: 0.8075 - val_loss: 0.4062 - val_acc: 0.8066\n",
      "Epoch 13/20\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8078\n",
      "Epoch 00013: val_acc did not improve from 0.80659\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4045 - acc: 0.8078 - val_loss: 0.4072 - val_acc: 0.8058\n",
      "Epoch 14/20\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.4042 - acc: 0.8078\n",
      "Epoch 00014: val_acc did not improve from 0.80659\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4042 - acc: 0.8078 - val_loss: 0.4092 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8080\n",
      "Epoch 00015: val_acc improved from 0.80659 to 0.80660, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4040 - acc: 0.8080 - val_loss: 0.4061 - val_acc: 0.8066\n",
      "Epoch 16/20\n",
      "1996288/2000000 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.8083\n",
      "Epoch 00016: val_acc improved from 0.80660 to 0.80667, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4037 - acc: 0.8083 - val_loss: 0.4058 - val_acc: 0.8067\n",
      "Epoch 17/20\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8081\n",
      "Epoch 00017: val_acc did not improve from 0.80667\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4036 - acc: 0.8081 - val_loss: 0.4062 - val_acc: 0.8067\n",
      "Epoch 18/20\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8082\n",
      "Epoch 00018: val_acc improved from 0.80667 to 0.80700, saving model to models/weights_2_layers_20_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4034 - acc: 0.8082 - val_loss: 0.4056 - val_acc: 0.8070\n",
      "Epoch 19/20\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.8083\n",
      "Epoch 00019: val_acc did not improve from 0.80700\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4033 - acc: 0.8083 - val_loss: 0.4057 - val_acc: 0.8067\n",
      "Epoch 20/20\n",
      "1996160/2000000 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8083\n",
      "Epoch 00020: val_acc did not improve from 0.80700\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4031 - acc: 0.8083 - val_loss: 0.4061 - val_acc: 0.8061\n",
      "\n",
      "\n",
      "Starting with number of layers: 25\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.7926\n",
      "Epoch 00001: val_acc improved from -inf to 0.79956, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4306 - acc: 0.7926 - val_loss: 0.4187 - val_acc: 0.7996\n",
      "Epoch 2/20\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.4148 - acc: 0.8019\n",
      "Epoch 00002: val_acc improved from 0.79956 to 0.80301, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4148 - acc: 0.8019 - val_loss: 0.4120 - val_acc: 0.8030\n",
      "Epoch 3/20\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.4103 - acc: 0.8044\n",
      "Epoch 00003: val_acc improved from 0.80301 to 0.80437, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4103 - acc: 0.8045 - val_loss: 0.4098 - val_acc: 0.8044\n",
      "Epoch 4/20\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8058\n",
      "Epoch 00004: val_acc did not improve from 0.80437\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4077 - acc: 0.8058 - val_loss: 0.4113 - val_acc: 0.8035\n",
      "Epoch 5/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.4059 - acc: 0.8065\n",
      "Epoch 00005: val_acc improved from 0.80437 to 0.80677, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4059 - acc: 0.8065 - val_loss: 0.4058 - val_acc: 0.8068\n",
      "Epoch 6/20\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8074\n",
      "Epoch 00006: val_acc did not improve from 0.80677\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4044 - acc: 0.8074 - val_loss: 0.4067 - val_acc: 0.8060\n",
      "Epoch 7/20\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8081\n",
      "Epoch 00007: val_acc improved from 0.80677 to 0.80715, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4034 - acc: 0.8081 - val_loss: 0.4050 - val_acc: 0.8072\n",
      "Epoch 8/20\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.4026 - acc: 0.8083\n",
      "Epoch 00008: val_acc improved from 0.80715 to 0.80744, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4026 - acc: 0.8083 - val_loss: 0.4038 - val_acc: 0.8074\n",
      "Epoch 9/20\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.4019 - acc: 0.8090\n",
      "Epoch 00009: val_acc improved from 0.80744 to 0.80817, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4019 - acc: 0.8090 - val_loss: 0.4031 - val_acc: 0.8082\n",
      "Epoch 10/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8091\n",
      "Epoch 00010: val_acc did not improve from 0.80817\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4015 - acc: 0.8091 - val_loss: 0.4025 - val_acc: 0.8081\n",
      "Epoch 11/20\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8095\n",
      "Epoch 00011: val_acc did not improve from 0.80817\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4009 - acc: 0.8095 - val_loss: 0.4041 - val_acc: 0.8072\n",
      "Epoch 12/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.4005 - acc: 0.8097\n",
      "Epoch 00012: val_acc improved from 0.80817 to 0.80844, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4005 - acc: 0.8097 - val_loss: 0.4023 - val_acc: 0.8084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.4002 - acc: 0.8097\n",
      "Epoch 00013: val_acc did not improve from 0.80844\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4002 - acc: 0.8097 - val_loss: 0.4032 - val_acc: 0.8082\n",
      "Epoch 14/20\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.4000 - acc: 0.8099\n",
      "Epoch 00014: val_acc improved from 0.80844 to 0.80851, saving model to models/weights_2_layers_25_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4000 - acc: 0.8099 - val_loss: 0.4019 - val_acc: 0.8085\n",
      "Epoch 15/20\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8103\n",
      "Epoch 00015: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3995 - acc: 0.8103 - val_loss: 0.4037 - val_acc: 0.8079\n",
      "Epoch 16/20\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3994 - acc: 0.8102\n",
      "Epoch 00016: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3994 - acc: 0.8102 - val_loss: 0.4028 - val_acc: 0.8083\n",
      "Epoch 17/20\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8105\n",
      "Epoch 00017: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3992 - acc: 0.8105 - val_loss: 0.4028 - val_acc: 0.8084\n",
      "Epoch 18/20\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8105\n",
      "Epoch 00018: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3990 - acc: 0.8105 - val_loss: 0.4022 - val_acc: 0.8083\n",
      "Epoch 19/20\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3988 - acc: 0.8105\n",
      "Epoch 00019: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3988 - acc: 0.8106 - val_loss: 0.4022 - val_acc: 0.8080\n",
      "Epoch 20/20\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.8108\n",
      "Epoch 00020: val_acc did not improve from 0.80851\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3986 - acc: 0.8108 - val_loss: 0.4030 - val_acc: 0.8079\n",
      "\n",
      "\n",
      "Starting with number of layers: 30\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.4266 - acc: 0.7948\n",
      "Epoch 00001: val_acc improved from -inf to 0.79974, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4266 - acc: 0.7948 - val_loss: 0.4186 - val_acc: 0.7997\n",
      "Epoch 2/20\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8042\n",
      "Epoch 00002: val_acc improved from 0.79974 to 0.80467, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4107 - acc: 0.8042 - val_loss: 0.4096 - val_acc: 0.8047\n",
      "Epoch 3/20\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.4062 - acc: 0.8065\n",
      "Epoch 00003: val_acc improved from 0.80467 to 0.80673, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4062 - acc: 0.8065 - val_loss: 0.4059 - val_acc: 0.8067\n",
      "Epoch 4/20\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8079\n",
      "Epoch 00004: val_acc improved from 0.80673 to 0.80674, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.4036 - acc: 0.8079 - val_loss: 0.4058 - val_acc: 0.8067\n",
      "Epoch 5/20\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.4020 - acc: 0.8086\n",
      "Epoch 00005: val_acc improved from 0.80674 to 0.80771, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4020 - acc: 0.8086 - val_loss: 0.4042 - val_acc: 0.8077\n",
      "Epoch 6/20\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.4008 - acc: 0.8092\n",
      "Epoch 00006: val_acc improved from 0.80771 to 0.80853, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.4008 - acc: 0.8091 - val_loss: 0.4026 - val_acc: 0.8085\n",
      "Epoch 7/20\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8099\n",
      "Epoch 00007: val_acc did not improve from 0.80853\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3998 - acc: 0.8099 - val_loss: 0.4027 - val_acc: 0.8080\n",
      "Epoch 8/20\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3989 - acc: 0.8104\n",
      "Epoch 00008: val_acc improved from 0.80853 to 0.80966, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3990 - acc: 0.8104 - val_loss: 0.4007 - val_acc: 0.8097\n",
      "Epoch 9/20\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3983 - acc: 0.8107\n",
      "Epoch 00009: val_acc did not improve from 0.80966\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3983 - acc: 0.8107 - val_loss: 0.4020 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8111\n",
      "Epoch 00010: val_acc did not improve from 0.80966\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3978 - acc: 0.8111 - val_loss: 0.4041 - val_acc: 0.8071\n",
      "Epoch 11/20\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8114\n",
      "Epoch 00011: val_acc improved from 0.80966 to 0.80976, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3974 - acc: 0.8114 - val_loss: 0.4004 - val_acc: 0.8098\n",
      "Epoch 12/20\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3968 - acc: 0.8116\n",
      "Epoch 00012: val_acc did not improve from 0.80976\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3969 - acc: 0.8116 - val_loss: 0.4008 - val_acc: 0.8096\n",
      "Epoch 13/20\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8119\n",
      "Epoch 00013: val_acc improved from 0.80976 to 0.81020, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3965 - acc: 0.8119 - val_loss: 0.3996 - val_acc: 0.8102\n",
      "Epoch 14/20\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8121\n",
      "Epoch 00014: val_acc did not improve from 0.81020\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3961 - acc: 0.8121 - val_loss: 0.4004 - val_acc: 0.8094\n",
      "Epoch 15/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8122\n",
      "Epoch 00015: val_acc did not improve from 0.81020\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3958 - acc: 0.8122 - val_loss: 0.4012 - val_acc: 0.8095\n",
      "Epoch 16/20\n",
      "1996288/2000000 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8124\n",
      "Epoch 00016: val_acc improved from 0.81020 to 0.81073, saving model to models/weights_2_layers_30_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3956 - acc: 0.8124 - val_loss: 0.3983 - val_acc: 0.8107\n",
      "Epoch 17/20\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8124\n",
      "Epoch 00017: val_acc did not improve from 0.81073\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3954 - acc: 0.8124 - val_loss: 0.3998 - val_acc: 0.8102\n",
      "Epoch 18/20\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8125\n",
      "Epoch 00018: val_acc did not improve from 0.81073\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.3951 - acc: 0.8126 - val_loss: 0.4013 - val_acc: 0.8094\n",
      "Epoch 19/20\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8127\n",
      "Epoch 00019: val_acc did not improve from 0.81073\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3950 - acc: 0.8127 - val_loss: 0.3989 - val_acc: 0.8104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3946 - acc: 0.8128\n",
      "Epoch 00020: val_acc did not improve from 0.81073\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3946 - acc: 0.8128 - val_loss: 0.3990 - val_acc: 0.8104\n",
      "\n",
      "\n",
      "Starting with number of layers: 35\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.4257 - acc: 0.7955\n",
      "Epoch 00001: val_acc improved from -inf to 0.80266, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 29s 14us/sample - loss: 0.4256 - acc: 0.7955 - val_loss: 0.4129 - val_acc: 0.8027\n",
      "Epoch 2/20\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8041\n",
      "Epoch 00002: val_acc improved from 0.80266 to 0.80488, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4105 - acc: 0.8041 - val_loss: 0.4084 - val_acc: 0.8049\n",
      "Epoch 3/20\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8070\n",
      "Epoch 00003: val_acc improved from 0.80488 to 0.80756, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4054 - acc: 0.8070 - val_loss: 0.4042 - val_acc: 0.8076\n",
      "Epoch 4/20\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8084\n",
      "Epoch 00004: val_acc did not improve from 0.80756\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4025 - acc: 0.8084 - val_loss: 0.4052 - val_acc: 0.8069\n",
      "Epoch 5/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.4007 - acc: 0.8095\n",
      "Epoch 00005: val_acc improved from 0.80756 to 0.80895, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.4007 - acc: 0.8095 - val_loss: 0.4022 - val_acc: 0.8089\n",
      "Epoch 6/20\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8105\n",
      "Epoch 00006: val_acc improved from 0.80895 to 0.81028, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3991 - acc: 0.8105 - val_loss: 0.4004 - val_acc: 0.8103\n",
      "Epoch 7/20\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8111\n",
      "Epoch 00007: val_acc did not improve from 0.81028\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3982 - acc: 0.8111 - val_loss: 0.4059 - val_acc: 0.8064\n",
      "Epoch 8/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8115\n",
      "Epoch 00008: val_acc did not improve from 0.81028\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3973 - acc: 0.8115 - val_loss: 0.3999 - val_acc: 0.8100\n",
      "Epoch 9/20\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8118\n",
      "Epoch 00009: val_acc improved from 0.81028 to 0.81072, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3966 - acc: 0.8118 - val_loss: 0.3987 - val_acc: 0.8107\n",
      "Epoch 10/20\n",
      "1996032/2000000 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8122\n",
      "Epoch 00010: val_acc did not improve from 0.81072\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3961 - acc: 0.8122 - val_loss: 0.3991 - val_acc: 0.8105\n",
      "Epoch 11/20\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8124\n",
      "Epoch 00011: val_acc did not improve from 0.81072\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3954 - acc: 0.8124 - val_loss: 0.3991 - val_acc: 0.8102\n",
      "Epoch 12/20\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8125\n",
      "Epoch 00012: val_acc improved from 0.81072 to 0.81086, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 28s 14us/sample - loss: 0.3951 - acc: 0.8125 - val_loss: 0.3991 - val_acc: 0.8109\n",
      "Epoch 13/20\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3946 - acc: 0.8131\n",
      "Epoch 00013: val_acc did not improve from 0.81086\n",
      "2000000/2000000 [==============================] - 29s 14us/sample - loss: 0.3946 - acc: 0.8131 - val_loss: 0.3989 - val_acc: 0.8102\n",
      "Epoch 14/20\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8132\n",
      "Epoch 00014: val_acc improved from 0.81086 to 0.81128, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3943 - acc: 0.8132 - val_loss: 0.3981 - val_acc: 0.8113\n",
      "Epoch 15/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3940 - acc: 0.8134\n",
      "Epoch 00015: val_acc did not improve from 0.81128\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3940 - acc: 0.8134 - val_loss: 0.3975 - val_acc: 0.8111\n",
      "Epoch 16/20\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8134\n",
      "Epoch 00016: val_acc did not improve from 0.81128\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3937 - acc: 0.8134 - val_loss: 0.3976 - val_acc: 0.8112\n",
      "Epoch 17/20\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8136\n",
      "Epoch 00017: val_acc did not improve from 0.81128\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3935 - acc: 0.8136 - val_loss: 0.3977 - val_acc: 0.8112\n",
      "Epoch 18/20\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3933 - acc: 0.8137\n",
      "Epoch 00018: val_acc did not improve from 0.81128\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3933 - acc: 0.8137 - val_loss: 0.3975 - val_acc: 0.8112\n",
      "Epoch 19/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3930 - acc: 0.8138\n",
      "Epoch 00019: val_acc improved from 0.81128 to 0.81159, saving model to models/weights_2_layers_35_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3930 - acc: 0.8138 - val_loss: 0.3974 - val_acc: 0.8116\n",
      "Epoch 20/20\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8141\n",
      "Epoch 00020: val_acc did not improve from 0.81159\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3929 - acc: 0.8141 - val_loss: 0.3992 - val_acc: 0.8106\n",
      "\n",
      "\n",
      "Starting with number of layers: 40\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.7948\n",
      "Epoch 00001: val_acc improved from -inf to 0.80048, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.4258 - acc: 0.7948 - val_loss: 0.4179 - val_acc: 0.8005\n",
      "Epoch 2/20\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8045\n",
      "Epoch 00002: val_acc improved from 0.80048 to 0.80570, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4099 - acc: 0.8045 - val_loss: 0.4074 - val_acc: 0.8057\n",
      "Epoch 3/20\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8075\n",
      "Epoch 00003: val_acc improved from 0.80570 to 0.80819, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.4045 - acc: 0.8075 - val_loss: 0.4028 - val_acc: 0.8082\n",
      "Epoch 4/20\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8092\n",
      "Epoch 00004: val_acc improved from 0.80819 to 0.80888, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.4013 - acc: 0.8092 - val_loss: 0.4016 - val_acc: 0.8089\n",
      "Epoch 5/20\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8104\n",
      "Epoch 00005: val_acc did not improve from 0.80888\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3991 - acc: 0.8104 - val_loss: 0.4041 - val_acc: 0.8079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8112\n",
      "Epoch 00006: val_acc improved from 0.80888 to 0.80948, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3975 - acc: 0.8112 - val_loss: 0.3998 - val_acc: 0.8095\n",
      "Epoch 7/20\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3963 - acc: 0.8119\n",
      "Epoch 00007: val_acc improved from 0.80948 to 0.81059, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 39s 19us/sample - loss: 0.3963 - acc: 0.8119 - val_loss: 0.3986 - val_acc: 0.8106\n",
      "Epoch 8/20\n",
      "1996160/2000000 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8124\n",
      "Epoch 00008: val_acc improved from 0.81059 to 0.81066, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 44s 22us/sample - loss: 0.3954 - acc: 0.8124 - val_loss: 0.3982 - val_acc: 0.8107\n",
      "Epoch 9/20\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8132\n",
      "Epoch 00009: val_acc improved from 0.81066 to 0.81095, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 35s 17us/sample - loss: 0.3947 - acc: 0.8132 - val_loss: 0.3974 - val_acc: 0.8109\n",
      "Epoch 10/20\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3942 - acc: 0.8132\n",
      "Epoch 00010: val_acc improved from 0.81095 to 0.81107, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3941 - acc: 0.8132 - val_loss: 0.3974 - val_acc: 0.8111\n",
      "Epoch 11/20\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8134\n",
      "Epoch 00011: val_acc improved from 0.81107 to 0.81115, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3935 - acc: 0.8134 - val_loss: 0.3982 - val_acc: 0.8111\n",
      "Epoch 12/20\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3930 - acc: 0.8139\n",
      "Epoch 00012: val_acc improved from 0.81115 to 0.81174, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3930 - acc: 0.8139 - val_loss: 0.3961 - val_acc: 0.8117\n",
      "Epoch 13/20\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3925 - acc: 0.8140\n",
      "Epoch 00013: val_acc did not improve from 0.81174\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3925 - acc: 0.8140 - val_loss: 0.3965 - val_acc: 0.8115\n",
      "Epoch 14/20\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8141\n",
      "Epoch 00014: val_acc improved from 0.81174 to 0.81211, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3922 - acc: 0.8141 - val_loss: 0.3963 - val_acc: 0.8121\n",
      "Epoch 15/20\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8143\n",
      "Epoch 00015: val_acc did not improve from 0.81211\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3919 - acc: 0.8143 - val_loss: 0.3960 - val_acc: 0.8116\n",
      "Epoch 16/20\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3915 - acc: 0.8145\n",
      "Epoch 00016: val_acc did not improve from 0.81211\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3915 - acc: 0.8145 - val_loss: 0.3961 - val_acc: 0.8113\n",
      "Epoch 17/20\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8147\n",
      "Epoch 00017: val_acc did not improve from 0.81211\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3913 - acc: 0.8147 - val_loss: 0.3963 - val_acc: 0.8115\n",
      "Epoch 18/20\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8149\n",
      "Epoch 00018: val_acc did not improve from 0.81211\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3910 - acc: 0.8149 - val_loss: 0.3974 - val_acc: 0.8118\n",
      "Epoch 19/20\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8153\n",
      "Epoch 00019: val_acc improved from 0.81211 to 0.81217, saving model to models/weights_2_layers_40_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3908 - acc: 0.8153 - val_loss: 0.3953 - val_acc: 0.8122\n",
      "Epoch 20/20\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.8150\n",
      "Epoch 00020: val_acc did not improve from 0.81217\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3906 - acc: 0.8150 - val_loss: 0.3971 - val_acc: 0.8112\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# now perform training on the new features vectors.\n",
    "\n",
    "# Build a \"deep\" neural network with 2 hidden layers. When we see that it somehow works,\n",
    "# we can start doing some cross validation on it.\n",
    "\n",
    "for layer_size in range(15, 41, 5):\n",
    "    \n",
    "    print(\"\\n\\nStarting with number of layers: {}\".format(layer_size))\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(sentence_train_x.shape[1],)),   # the input shape is the number of words in the bow dictionary\n",
    "        keras.layers.Dense(layer_size, activation='relu'),\n",
    "        keras.layers.Dense(layer_size, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')   # Only 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "    overfitting_occurrences = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    filepath=\"models/weights_2_layers_{}_big\".format(layer_size)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x=sentence_train_x,\n",
    "              y=sentence_train_y,\n",
    "              validation_data=(sentence_test_x,  sentence_test_y),\n",
    "              callbacks=callbacks_list,\n",
    "              epochs=20,\n",
    "              use_multiprocessing=True,\n",
    "              batch_size=128)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To execute this after having trained the above model\n",
    "\n",
    "After having decided which one is the best model to use, just load the correct model, set the parameters of the model_star so that it matches the one of the best model, and compute the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate exactl the best model\n",
    "model_star = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(sentence_train_x.shape[1],)),   # the input shape is the number of words in the bow dictionary\n",
    "        keras.layers.Dense(40, activation='relu'),\n",
    "        keras.layers.Dense(40, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')   # Only 0 and 1\n",
    "    ])\n",
    "\n",
    "model_star.load_weights('models/weights_2_layers_40_big')\n",
    "\n",
    "model_star.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7ffa408c1610>\n"
     ]
    }
   ],
   "source": [
    "print(model_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 11s - loss: 0.4045 - acc: 0.8079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.0681679e-02, 9.5931840e-01],\n",
       "       [9.9999571e-01, 4.2639813e-06],\n",
       "       [7.2958276e-02, 9.2704177e-01],\n",
       "       ...,\n",
       "       [3.4315959e-01, 6.5684032e-01],\n",
       "       [6.1612552e-01, 3.8387451e-01],\n",
       "       [6.4644866e-02, 9.3535513e-01]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it on the test dataset to see if it gives the same best results.\n",
    "model_star.evaluate(sentence_test_x,  sentence_test_y, verbose=2)[1]\n",
    "model_star.predict(sentence_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of zero sentences (the sentences which have 0 words in our vocabulary) is 22\n"
     ]
    }
   ],
   "source": [
    "sentence_submission_x = create_sentence_vectors_submission(df_test['sentence'],\n",
    "                                                           word_vector_size,\n",
    "                                                           w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96396494, 0.03603501],\n",
       "       [0.6632302 , 0.33676985],\n",
       "       [0.7554848 , 0.24451518],\n",
       "       ...,\n",
       "       [0.9986198 , 0.00138015],\n",
       "       [0.05644046, 0.9435596 ],\n",
       "       [0.9798126 , 0.02018739]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_star.predict(sentence_submission_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, 1, -1, -1, -1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction\n",
       "0    1          -1\n",
       "1    2          -1\n",
       "2    3          -1\n",
       "3    4           1\n",
       "4    5          -1\n",
       "5    6          -1\n",
       "6    7          -1\n",
       "7    8           1\n",
       "8    9           1\n",
       "9   10           1\n",
       "10  11           1\n",
       "11  12           1\n",
       "12  13           1\n",
       "13  14          -1\n",
       "14  15           1\n",
       "15  16           1\n",
       "16  17          -1\n",
       "17  18           1\n",
       "18  19           1\n",
       "19  20          -1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for el in model_star.predict(sentence_submission_x):\n",
    "    predictions.append(-1 if el[0] > el[1] else 1)\n",
    "\n",
    "print(predictions[:10])\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Id\": df_test['label'],\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
