{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from helpers import count_unique_words, count_unique_ngrams, \\\n",
    "            build_unique_ngrams, create_sentence_vectors, create_sentence_vectors_submission\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import gensim   # Not sure whether it is better to use gensim or tensorflow :/\n",
    "import logging\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    " \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-16 11:10:52,584 : INFO : loading Word2Vec object from models/w2v_model_epochs_10_win_10_sg_300.model\n",
      "2019-12-16 11:10:53,321 : INFO : loading wv recursively from models/w2v_model_epochs_10_win_10_sg_300.model.wv.* with mmap=None\n",
      "2019-12-16 11:10:53,321 : INFO : loading vectors from models/w2v_model_epochs_10_win_10_sg_300.model.wv.vectors.npy with mmap=None\n",
      "2019-12-16 11:10:53,430 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-12-16 11:10:53,430 : INFO : loading vocabulary recursively from models/w2v_model_epochs_10_win_10_sg_300.model.vocabulary.* with mmap=None\n",
      "2019-12-16 11:10:53,431 : INFO : loading trainables recursively from models/w2v_model_epochs_10_win_10_sg_300.model.trainables.* with mmap=None\n",
      "2019-12-16 11:10:53,431 : INFO : loading syn1neg from models/w2v_model_epochs_10_win_10_sg_300.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-12-16 11:10:53,531 : INFO : setting ignored attribute cum_table to None\n",
      "2019-12-16 11:10:53,532 : INFO : loaded models/w2v_model_epochs_10_win_10_sg_300.model\n"
     ]
    }
   ],
   "source": [
    "# For non binary models\n",
    "w2v_model = Word2Vec.load(\"models/w2v_model_epochs_10_win_10_sg_300.model\")\n",
    "\n",
    "# For binary models\n",
    "#w2v_model = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_vector_size = w2v_model.wv.vectors.shape[1]\n",
    "word_vector_size = 300\n",
    "word_vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('keyboar', 0.5493345260620117),\n",
       " ('adesso', 0.528719961643219),\n",
       " ('eltrex-tech', 0.5182769894599915),\n",
       " ('pz30au', 0.5138871669769287),\n",
       " ('akai', 0.5134224891662598),\n",
       " ('73p4067', 0.5131996870040894),\n",
       " ('q29', 0.5130102634429932),\n",
       " ('btkey', 0.5105351209640503),\n",
       " ('icekey', 0.5092136859893799),\n",
       " ('olikey', 0.5090413689613342)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"keyboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is unfortunately very high memory consumptive\n",
    "\n",
    "# Test here is not the unlabelled testset, but rather the 0.8 split of the original training set\n",
    "\n",
    "sentence_train_x = np.load(\"np_arrays/sentences_train_x_0_8_300.npy\")\n",
    "sentence_train_y = np.load(\"np_arrays/sentences_train_y_0_8_300.npy\")\n",
    "\n",
    "sentence_test_x = np.load(\"np_arrays/sentences_test_x_0_2_300.npy\")\n",
    "sentence_test_y = np.load(\"np_arrays/sentences_test_y_0_2_300.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just print how many 0 we have, just to be sure that we have shuffled the dataset\n",
    "y_ = np.argmax(sentence_train_y, axis=-1)\n",
    "len(y_[y_==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting with number of layers: 40\n",
      "WARNING:tensorflow:From /home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-16 12:34:08,902 : WARNING : From /home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000000 samples, validate on 500000 samples\n",
      "WARNING:tensorflow:From /home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-16 12:34:09,115 : WARNING : From /home/stefano/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.4185 - acc: 0.7998\n",
      "Epoch 00001: val_acc improved from -inf to 0.80707, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.4185 - acc: 0.7998 - val_loss: 0.4067 - val_acc: 0.8071\n",
      "Epoch 2/50\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.4020 - acc: 0.8095\n",
      "Epoch 00002: val_acc improved from 0.80707 to 0.80948, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.4020 - acc: 0.8095 - val_loss: 0.4018 - val_acc: 0.8095\n",
      "Epoch 3/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8125\n",
      "Epoch 00003: val_acc improved from 0.80948 to 0.81208, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3962 - acc: 0.8125 - val_loss: 0.3966 - val_acc: 0.8121\n",
      "Epoch 4/50\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8143\n",
      "Epoch 00004: val_acc did not improve from 0.81208\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3931 - acc: 0.8143 - val_loss: 0.3972 - val_acc: 0.8111\n",
      "Epoch 5/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8154\n",
      "Epoch 00005: val_acc improved from 0.81208 to 0.81390, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3909 - acc: 0.8154 - val_loss: 0.3936 - val_acc: 0.8139\n",
      "Epoch 6/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8162\n",
      "Epoch 00006: val_acc improved from 0.81390 to 0.81424, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3893 - acc: 0.8162 - val_loss: 0.3930 - val_acc: 0.8142\n",
      "Epoch 7/50\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3882 - acc: 0.8168\n",
      "Epoch 00007: val_acc improved from 0.81424 to 0.81469, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3881 - acc: 0.8168 - val_loss: 0.3922 - val_acc: 0.8147\n",
      "Epoch 8/50\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3871 - acc: 0.8175\n",
      "Epoch 00008: val_acc improved from 0.81469 to 0.81500, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3871 - acc: 0.8175 - val_loss: 0.3919 - val_acc: 0.8150\n",
      "Epoch 9/50\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8178\n",
      "Epoch 00009: val_acc did not improve from 0.81500\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3862 - acc: 0.8178 - val_loss: 0.3935 - val_acc: 0.8137\n",
      "Epoch 10/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3855 - acc: 0.8185\n",
      "Epoch 00010: val_acc improved from 0.81500 to 0.81577, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3855 - acc: 0.8185 - val_loss: 0.3905 - val_acc: 0.8158\n",
      "Epoch 11/50\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8186\n",
      "Epoch 00011: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3849 - acc: 0.8186 - val_loss: 0.3924 - val_acc: 0.8144\n",
      "Epoch 12/50\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3844 - acc: 0.8188\n",
      "Epoch 00012: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3844 - acc: 0.8188 - val_loss: 0.3924 - val_acc: 0.8143\n",
      "Epoch 13/50\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.8193\n",
      "Epoch 00013: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3839 - acc: 0.8193 - val_loss: 0.3917 - val_acc: 0.8154\n",
      "Epoch 14/50\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8194\n",
      "Epoch 00014: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 34s 17us/sample - loss: 0.3835 - acc: 0.8194 - val_loss: 0.3910 - val_acc: 0.8154\n",
      "Epoch 15/50\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8195\n",
      "Epoch 00015: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3832 - acc: 0.8195 - val_loss: 0.3898 - val_acc: 0.8158\n",
      "Epoch 16/50\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8197\n",
      "Epoch 00016: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 29s 15us/sample - loss: 0.3828 - acc: 0.8197 - val_loss: 0.3916 - val_acc: 0.8147\n",
      "Epoch 17/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3825 - acc: 0.8199\n",
      "Epoch 00017: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3825 - acc: 0.8199 - val_loss: 0.3900 - val_acc: 0.8155\n",
      "Epoch 18/50\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3822 - acc: 0.8199\n",
      "Epoch 00018: val_acc did not improve from 0.81577\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3822 - acc: 0.8199 - val_loss: 0.3906 - val_acc: 0.8157\n",
      "Epoch 19/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8201\n",
      "Epoch 00019: val_acc improved from 0.81577 to 0.81630, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3820 - acc: 0.8202 - val_loss: 0.3893 - val_acc: 0.8163\n",
      "Epoch 20/50\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8205\n",
      "Epoch 00020: val_acc improved from 0.81630 to 0.81637, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3817 - acc: 0.8204 - val_loss: 0.3890 - val_acc: 0.8164\n",
      "Epoch 21/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3815 - acc: 0.8206\n",
      "Epoch 00021: val_acc did not improve from 0.81637\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3815 - acc: 0.8206 - val_loss: 0.3919 - val_acc: 0.8152\n",
      "Epoch 22/50\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.8206\n",
      "Epoch 00022: val_acc did not improve from 0.81637\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3812 - acc: 0.8206 - val_loss: 0.3908 - val_acc: 0.8159\n",
      "Epoch 23/50\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8208\n",
      "Epoch 00023: val_acc did not improve from 0.81637\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3810 - acc: 0.8208 - val_loss: 0.3894 - val_acc: 0.8160\n",
      "Epoch 24/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.8208\n",
      "Epoch 00024: val_acc did not improve from 0.81637\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3808 - acc: 0.8208 - val_loss: 0.3941 - val_acc: 0.8134\n",
      "Epoch 25/50\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8208\n",
      "Epoch 00025: val_acc improved from 0.81637 to 0.81702, saving model to models/weights_3_layers_of_size_40_big\n",
      "2000000/2000000 [==============================] - 34s 17us/sample - loss: 0.3807 - acc: 0.8208 - val_loss: 0.3886 - val_acc: 0.8170\n",
      "Epoch 26/50\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8211\n",
      "Epoch 00026: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 34s 17us/sample - loss: 0.3805 - acc: 0.8211 - val_loss: 0.3899 - val_acc: 0.8160\n",
      "Epoch 27/50\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8212\n",
      "Epoch 00027: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3804 - acc: 0.8212 - val_loss: 0.3896 - val_acc: 0.8165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8211\n",
      "Epoch 00028: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3802 - acc: 0.8211 - val_loss: 0.3903 - val_acc: 0.8156\n",
      "Epoch 29/50\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8212\n",
      "Epoch 00029: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3801 - acc: 0.8212 - val_loss: 0.3899 - val_acc: 0.8160\n",
      "Epoch 30/50\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8212\n",
      "Epoch 00030: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3800 - acc: 0.8213 - val_loss: 0.3929 - val_acc: 0.8148\n",
      "Epoch 31/50\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8213\n",
      "Epoch 00031: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3798 - acc: 0.8213 - val_loss: 0.3905 - val_acc: 0.8159\n",
      "Epoch 32/50\n",
      "1996928/2000000 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8215\n",
      "Epoch 00032: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3797 - acc: 0.8215 - val_loss: 0.3902 - val_acc: 0.8159\n",
      "Epoch 33/50\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8215\n",
      "Epoch 00033: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3796 - acc: 0.8215 - val_loss: 0.3907 - val_acc: 0.8164\n",
      "Epoch 34/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8217\n",
      "Epoch 00034: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3795 - acc: 0.8217 - val_loss: 0.3895 - val_acc: 0.8167\n",
      "Epoch 35/50\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8217\n",
      "Epoch 00035: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3794 - acc: 0.8217 - val_loss: 0.3897 - val_acc: 0.8164\n",
      "Epoch 36/50\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8216\n",
      "Epoch 00036: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3793 - acc: 0.8216 - val_loss: 0.3918 - val_acc: 0.8152\n",
      "Epoch 37/50\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8217\n",
      "Epoch 00037: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3792 - acc: 0.8217 - val_loss: 0.3892 - val_acc: 0.8169\n",
      "Epoch 38/50\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8218\n",
      "Epoch 00038: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3792 - acc: 0.8218 - val_loss: 0.3904 - val_acc: 0.8159\n",
      "Epoch 39/50\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3791 - acc: 0.8216\n",
      "Epoch 00039: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3791 - acc: 0.8216 - val_loss: 0.3905 - val_acc: 0.8159\n",
      "Epoch 40/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8218\n",
      "Epoch 00040: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3790 - acc: 0.8218 - val_loss: 0.3896 - val_acc: 0.8164\n",
      "Epoch 41/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8218\n",
      "Epoch 00041: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3790 - acc: 0.8218 - val_loss: 0.3901 - val_acc: 0.8161\n",
      "Epoch 42/50\n",
      "1996288/2000000 [============================>.] - ETA: 0s - loss: 0.3789 - acc: 0.8218\n",
      "Epoch 00042: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3789 - acc: 0.8218 - val_loss: 0.3892 - val_acc: 0.8163\n",
      "Epoch 43/50\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3787 - acc: 0.8219\n",
      "Epoch 00043: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3787 - acc: 0.8219 - val_loss: 0.3909 - val_acc: 0.8157\n",
      "Epoch 44/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3787 - acc: 0.8219\n",
      "Epoch 00044: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3787 - acc: 0.8219 - val_loss: 0.3893 - val_acc: 0.8163\n",
      "Epoch 45/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3787 - acc: 0.8221\n",
      "Epoch 00045: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3787 - acc: 0.8221 - val_loss: 0.3893 - val_acc: 0.8167\n",
      "Epoch 46/50\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8218\n",
      "Epoch 00046: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3785 - acc: 0.8218 - val_loss: 0.3898 - val_acc: 0.8163\n",
      "Epoch 47/50\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8220\n",
      "Epoch 00047: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3784 - acc: 0.8220 - val_loss: 0.3896 - val_acc: 0.8169\n",
      "Epoch 48/50\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8223\n",
      "Epoch 00048: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3784 - acc: 0.8223 - val_loss: 0.3896 - val_acc: 0.8167\n",
      "Epoch 49/50\n",
      "1997696/2000000 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8222\n",
      "Epoch 00049: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3783 - acc: 0.8222 - val_loss: 0.3901 - val_acc: 0.8159\n",
      "Epoch 50/50\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.3783 - acc: 0.8223\n",
      "Epoch 00050: val_acc did not improve from 0.81702\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3783 - acc: 0.8223 - val_loss: 0.3893 - val_acc: 0.8164\n",
      "\n",
      "\n",
      "Starting with number of layers: 45\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/50\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.4177 - acc: 0.8004\n",
      "Epoch 00001: val_acc improved from -inf to 0.80858, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.4177 - acc: 0.8004 - val_loss: 0.4038 - val_acc: 0.8086\n",
      "Epoch 2/50\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.4007 - acc: 0.8103\n",
      "Epoch 00002: val_acc improved from 0.80858 to 0.81050, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.4006 - acc: 0.8103 - val_loss: 0.4002 - val_acc: 0.8105\n",
      "Epoch 3/50\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3950 - acc: 0.8133\n",
      "Epoch 00003: val_acc improved from 0.81050 to 0.81161, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3950 - acc: 0.8133 - val_loss: 0.3981 - val_acc: 0.8116\n",
      "Epoch 4/50\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8152\n",
      "Epoch 00004: val_acc improved from 0.81161 to 0.81406, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3916 - acc: 0.8152 - val_loss: 0.3942 - val_acc: 0.8141\n",
      "Epoch 5/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8164\n",
      "Epoch 00005: val_acc did not improve from 0.81406\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3893 - acc: 0.8164 - val_loss: 0.3954 - val_acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8173\n",
      "Epoch 00006: val_acc improved from 0.81406 to 0.81504, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3877 - acc: 0.8173 - val_loss: 0.3920 - val_acc: 0.8150\n",
      "Epoch 7/50\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8180\n",
      "Epoch 00007: val_acc did not improve from 0.81504\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3863 - acc: 0.8180 - val_loss: 0.3940 - val_acc: 0.8135\n",
      "Epoch 8/50\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8188\n",
      "Epoch 00008: val_acc did not improve from 0.81504\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3852 - acc: 0.8188 - val_loss: 0.3939 - val_acc: 0.8142\n",
      "Epoch 9/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3844 - acc: 0.8191\n",
      "Epoch 00009: val_acc improved from 0.81504 to 0.81551, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3844 - acc: 0.8191 - val_loss: 0.3917 - val_acc: 0.8155\n",
      "Epoch 10/50\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8196\n",
      "Epoch 00010: val_acc improved from 0.81551 to 0.81574, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3836 - acc: 0.8196 - val_loss: 0.3906 - val_acc: 0.8157\n",
      "Epoch 11/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8198\n",
      "Epoch 00011: val_acc did not improve from 0.81574\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3830 - acc: 0.8198 - val_loss: 0.3910 - val_acc: 0.8156\n",
      "Epoch 12/50\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3824 - acc: 0.8201\n",
      "Epoch 00012: val_acc did not improve from 0.81574\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3824 - acc: 0.8201 - val_loss: 0.3907 - val_acc: 0.8151\n",
      "Epoch 13/50\n",
      "1996160/2000000 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8203\n",
      "Epoch 00013: val_acc improved from 0.81574 to 0.81639, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3819 - acc: 0.8203 - val_loss: 0.3905 - val_acc: 0.8164\n",
      "Epoch 14/50\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8208\n",
      "Epoch 00014: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3816 - acc: 0.8208 - val_loss: 0.3900 - val_acc: 0.8160\n",
      "Epoch 15/50\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8209\n",
      "Epoch 00015: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3810 - acc: 0.8209 - val_loss: 0.3887 - val_acc: 0.8158\n",
      "Epoch 16/50\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8211\n",
      "Epoch 00016: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3806 - acc: 0.8211 - val_loss: 0.4004 - val_acc: 0.8100\n",
      "Epoch 17/50\n",
      "1999488/2000000 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8212\n",
      "Epoch 00017: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3804 - acc: 0.8212 - val_loss: 0.3900 - val_acc: 0.8155\n",
      "Epoch 18/50\n",
      "1998592/2000000 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8214\n",
      "Epoch 00018: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3800 - acc: 0.8215 - val_loss: 0.3889 - val_acc: 0.8162\n",
      "Epoch 19/50\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8218\n",
      "Epoch 00019: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3797 - acc: 0.8218 - val_loss: 0.3912 - val_acc: 0.8154\n",
      "Epoch 20/50\n",
      "1998080/2000000 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8216\n",
      "Epoch 00020: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3795 - acc: 0.8216 - val_loss: 0.3913 - val_acc: 0.8159\n",
      "Epoch 21/50\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8219\n",
      "Epoch 00021: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 33s 17us/sample - loss: 0.3793 - acc: 0.8219 - val_loss: 0.3897 - val_acc: 0.8163\n",
      "Epoch 22/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8220\n",
      "Epoch 00022: val_acc did not improve from 0.81639\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3790 - acc: 0.8220 - val_loss: 0.3901 - val_acc: 0.8161\n",
      "Epoch 23/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8221\n",
      "Epoch 00023: val_acc improved from 0.81639 to 0.81653, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3788 - acc: 0.8221 - val_loss: 0.3889 - val_acc: 0.8165\n",
      "Epoch 24/50\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8221\n",
      "Epoch 00024: val_acc improved from 0.81653 to 0.81661, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3786 - acc: 0.8221 - val_loss: 0.3890 - val_acc: 0.8166\n",
      "Epoch 25/50\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8222\n",
      "Epoch 00025: val_acc did not improve from 0.81661\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3784 - acc: 0.8222 - val_loss: 0.3900 - val_acc: 0.8160\n",
      "Epoch 26/50\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3783 - acc: 0.8224\n",
      "Epoch 00026: val_acc did not improve from 0.81661\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3783 - acc: 0.8224 - val_loss: 0.3927 - val_acc: 0.8142\n",
      "Epoch 27/50\n",
      "1998976/2000000 [============================>.] - ETA: 0s - loss: 0.3781 - acc: 0.8224\n",
      "Epoch 00027: val_acc did not improve from 0.81661\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3781 - acc: 0.8224 - val_loss: 0.3895 - val_acc: 0.8161\n",
      "Epoch 28/50\n",
      "1996544/2000000 [============================>.] - ETA: 0s - loss: 0.3779 - acc: 0.8226\n",
      "Epoch 00028: val_acc did not improve from 0.81661\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3779 - acc: 0.8226 - val_loss: 0.3897 - val_acc: 0.8161\n",
      "Epoch 29/50\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3778 - acc: 0.8226\n",
      "Epoch 00029: val_acc improved from 0.81661 to 0.81687, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3778 - acc: 0.8226 - val_loss: 0.3888 - val_acc: 0.8169\n",
      "Epoch 30/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8225\n",
      "Epoch 00030: val_acc improved from 0.81687 to 0.81715, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3776 - acc: 0.8225 - val_loss: 0.3885 - val_acc: 0.8172\n",
      "Epoch 31/50\n",
      "1997568/2000000 [============================>.] - ETA: 0s - loss: 0.3775 - acc: 0.8226\n",
      "Epoch 00031: val_acc improved from 0.81715 to 0.81726, saving model to models/weights_3_layers_of_size_45_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3775 - acc: 0.8226 - val_loss: 0.3887 - val_acc: 0.8173\n",
      "Epoch 32/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3774 - acc: 0.8229\n",
      "Epoch 00032: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3774 - acc: 0.8229 - val_loss: 0.3897 - val_acc: 0.8163\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3772 - acc: 0.8228\n",
      "Epoch 00033: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3772 - acc: 0.8228 - val_loss: 0.3894 - val_acc: 0.8163\n",
      "Epoch 34/50\n",
      "1997056/2000000 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8230\n",
      "Epoch 00034: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3771 - acc: 0.8230 - val_loss: 0.3890 - val_acc: 0.8169\n",
      "Epoch 35/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3770 - acc: 0.8229\n",
      "Epoch 00035: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3770 - acc: 0.8229 - val_loss: 0.3893 - val_acc: 0.8164\n",
      "Epoch 36/50\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8229\n",
      "Epoch 00036: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3769 - acc: 0.8229 - val_loss: 0.3890 - val_acc: 0.8167\n",
      "Epoch 37/50\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3768 - acc: 0.8231\n",
      "Epoch 00037: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3768 - acc: 0.8231 - val_loss: 0.3879 - val_acc: 0.8170\n",
      "Epoch 38/50\n",
      "1999616/2000000 [============================>.] - ETA: 0s - loss: 0.3768 - acc: 0.8231\n",
      "Epoch 00038: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3768 - acc: 0.8231 - val_loss: 0.3922 - val_acc: 0.8148\n",
      "Epoch 39/50\n",
      "1998720/2000000 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8230\n",
      "Epoch 00039: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3766 - acc: 0.8230 - val_loss: 0.3886 - val_acc: 0.8166\n",
      "Epoch 40/50\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8232\n",
      "Epoch 00040: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3766 - acc: 0.8232 - val_loss: 0.3883 - val_acc: 0.8169\n",
      "Epoch 41/50\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8232\n",
      "Epoch 00041: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3765 - acc: 0.8232 - val_loss: 0.3888 - val_acc: 0.8166\n",
      "Epoch 42/50\n",
      "1996672/2000000 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8233\n",
      "Epoch 00042: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3764 - acc: 0.8232 - val_loss: 0.3885 - val_acc: 0.8167\n",
      "Epoch 43/50\n",
      "1997312/2000000 [============================>.] - ETA: 0s - loss: 0.3763 - acc: 0.8235\n",
      "Epoch 00043: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3763 - acc: 0.8234 - val_loss: 0.3893 - val_acc: 0.8162\n",
      "Epoch 44/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8235\n",
      "Epoch 00044: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3762 - acc: 0.8235 - val_loss: 0.3880 - val_acc: 0.8169\n",
      "Epoch 45/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8235\n",
      "Epoch 00045: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3761 - acc: 0.8235 - val_loss: 0.3901 - val_acc: 0.8165\n",
      "Epoch 46/50\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8234\n",
      "Epoch 00046: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3761 - acc: 0.8234 - val_loss: 0.3887 - val_acc: 0.8171\n",
      "Epoch 47/50\n",
      "1998208/2000000 [============================>.] - ETA: 0s - loss: 0.3759 - acc: 0.8235\n",
      "Epoch 00047: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3759 - acc: 0.8235 - val_loss: 0.3884 - val_acc: 0.8166\n",
      "Epoch 48/50\n",
      "1998336/2000000 [============================>.] - ETA: 0s - loss: 0.3759 - acc: 0.8236\n",
      "Epoch 00048: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3759 - acc: 0.8236 - val_loss: 0.3912 - val_acc: 0.8154\n",
      "Epoch 49/50\n",
      "1999744/2000000 [============================>.] - ETA: 0s - loss: 0.3759 - acc: 0.8236\n",
      "Epoch 00049: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3759 - acc: 0.8236 - val_loss: 0.3903 - val_acc: 0.8158\n",
      "Epoch 50/50\n",
      "1999232/2000000 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8237\n",
      "Epoch 00050: val_acc did not improve from 0.81726\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3758 - acc: 0.8237 - val_loss: 0.3889 - val_acc: 0.8166\n",
      "\n",
      "\n",
      "Starting with number of layers: 50\n",
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/50\n",
      "1998464/2000000 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.8006\n",
      "Epoch 00001: val_acc improved from -inf to 0.80752, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.4170 - acc: 0.8006 - val_loss: 0.4053 - val_acc: 0.8075\n",
      "Epoch 2/50\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8105\n",
      "Epoch 00002: val_acc improved from 0.80752 to 0.81106, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3995 - acc: 0.8105 - val_loss: 0.4001 - val_acc: 0.8111\n",
      "Epoch 3/50\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3933 - acc: 0.8138\n",
      "Epoch 00003: val_acc improved from 0.81106 to 0.81232, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3933 - acc: 0.8138 - val_loss: 0.3965 - val_acc: 0.8123\n",
      "Epoch 4/50\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3895 - acc: 0.8160\n",
      "Epoch 00004: val_acc improved from 0.81232 to 0.81438, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3895 - acc: 0.8160 - val_loss: 0.3923 - val_acc: 0.8144\n",
      "Epoch 5/50\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3871 - acc: 0.8174\n",
      "Epoch 00005: val_acc improved from 0.81438 to 0.81460, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3871 - acc: 0.8174 - val_loss: 0.3920 - val_acc: 0.8146\n",
      "Epoch 6/50\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8181\n",
      "Epoch 00006: val_acc improved from 0.81460 to 0.81526, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3854 - acc: 0.8181 - val_loss: 0.3911 - val_acc: 0.8153\n",
      "Epoch 7/50\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8192\n",
      "Epoch 00007: val_acc did not improve from 0.81526\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3840 - acc: 0.8192 - val_loss: 0.3915 - val_acc: 0.8151\n",
      "Epoch 8/50\n",
      "1999104/2000000 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8197\n",
      "Epoch 00008: val_acc improved from 0.81526 to 0.81590, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3828 - acc: 0.8197 - val_loss: 0.3892 - val_acc: 0.8159\n",
      "Epoch 9/50\n",
      "1999360/2000000 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8201\n",
      "Epoch 00009: val_acc improved from 0.81590 to 0.81600, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 34s 17us/sample - loss: 0.3819 - acc: 0.8201 - val_loss: 0.3900 - val_acc: 0.8160\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.8208\n",
      "Epoch 00010: val_acc improved from 0.81600 to 0.81607, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 30s 15us/sample - loss: 0.3811 - acc: 0.8208 - val_loss: 0.3890 - val_acc: 0.8161\n",
      "Epoch 11/50\n",
      "1996416/2000000 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8210\n",
      "Epoch 00011: val_acc improved from 0.81607 to 0.81662, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 31s 15us/sample - loss: 0.3804 - acc: 0.8210 - val_loss: 0.3883 - val_acc: 0.8166\n",
      "Epoch 12/50\n",
      "1997440/2000000 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8214\n",
      "Epoch 00012: val_acc improved from 0.81662 to 0.81685, saving model to models/weights_3_layers_of_size_50_big\n",
      "2000000/2000000 [==============================] - 31s 16us/sample - loss: 0.3798 - acc: 0.8214 - val_loss: 0.3895 - val_acc: 0.8168\n",
      "Epoch 13/50\n",
      "1997184/2000000 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8217\n",
      "Epoch 00013: val_acc did not improve from 0.81685\n",
      "2000000/2000000 [==============================] - 32s 16us/sample - loss: 0.3793 - acc: 0.8217 - val_loss: 0.3893 - val_acc: 0.8166\n",
      "Epoch 14/50\n",
      "1997952/2000000 [============================>.] - ETA: 0s - loss: 0.3789 - acc: 0.8220\n",
      "Epoch 00014: val_acc did not improve from 0.81685\n",
      "2000000/2000000 [==============================] - 33s 16us/sample - loss: 0.3789 - acc: 0.8220 - val_loss: 0.3891 - val_acc: 0.8167\n",
      "Epoch 15/50\n",
      "1243264/2000000 [=================>............] - ETA: 11s - loss: 0.3778 - acc: 0.8222"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a3b1628c4045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m               batch_size=128)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# now perform training on the new features vectors.\n",
    "\n",
    "# Build a \"deep\" neural network with 2 hidden layers. When we see that it somehow works,\n",
    "# we can start doing some cross validation on it.\n",
    "\n",
    "for layer_size in range(40, 101, 5):\n",
    "    \n",
    "    print(\"\\n\\nStarting with number of layers: {}\".format(layer_size))\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(sentence_train_x.shape[1],)),   # the input shape is the number of words in the bow dictionary\n",
    "        keras.layers.Dense(layer_size, activation='relu'),\n",
    "        keras.layers.Dense(layer_size, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')   # Only 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "    filepath=\"models/weights_{}_layers_of_size_{}_big\".format(len(model.layers), layer_size)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x=sentence_train_x,\n",
    "              y=sentence_train_y,\n",
    "              validation_data=(sentence_test_x,  sentence_test_y),\n",
    "              callbacks=callbacks_list,\n",
    "              epochs=50,\n",
    "              use_multiprocessing=True,\n",
    "              batch_size=128)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To execute this after having trained the above model\n",
    "\n",
    "After having decided which one is the best model to use, just load the correct model, set the parameters of the model_star so that it matches the one of the best model, and compute the results!\n",
    "\n",
    "(The below part needs to be rewritten to take advantage of the python modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate exactl the best model\n",
    "model_star = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(sentence_train_x.shape[1],)),   # the input shape is the number of words in the bow dictionary\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')   # Only 0 and 1\n",
    "    ])\n",
    "\n",
    "model_star.load_weights('models/weights_2_layers_100_big')\n",
    "\n",
    "model_star.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it on the test dataset to see if it gives the same best results.\n",
    "model_star.evaluate(sentence_test_x,  sentence_test_y, verbose=2)[1]\n",
    "model_star.predict(sentence_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET the test data and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cleaned = pd.read_pickle(\"dataframes/test_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_submission_x = create_sentence_vectors_submission(test_df_cleaned['sentence'], word_vector_size, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_submission_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_star.predict(sentence_submission_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for el in model_star.predict(sentence_submission_x):\n",
    "    predictions.append(-1 if el[0] > el[1] else 1)\n",
    "\n",
    "print(predictions[:10])\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Id\": test_df_cleaned['label'],\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
